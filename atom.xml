<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Jinxi Blog</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2021-08-26T16:47:17.661Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>Jinxi</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Hexo 使用笔记</title>
    <link href="http://example.com/2021/08/26/hexo%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/"/>
    <id>http://example.com/2021/08/26/hexo%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/</id>
    <published>2021-08-26T16:00:00.000Z</published>
    <updated>2021-08-26T16:47:17.661Z</updated>
    
    <content type="html"><![CDATA[<p>本地测试：<code>hexo s</code></p><p>发布到GitHub：<code>hexo clean &amp;&amp; hexo g &amp;&amp; hexo d</code></p><span id="more"></span>]]></content>
    
    
    <summary type="html">&lt;p&gt;本地测试：&lt;code&gt;hexo s&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;发布到GitHub：&lt;code&gt;hexo clean &amp;amp;&amp;amp; hexo g &amp;amp;&amp;amp; hexo d&lt;/code&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="Hexo" scheme="http://example.com/categories/Hexo/"/>
    
    
    <category term="学习笔记" scheme="http://example.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>论文阅读笔记《REFORMER THE EFFICIENT TRANSFORMER》</title>
    <link href="http://example.com/2021/08/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%8AREFORMER-THE-EFFICIENT-TRANSFORMER%E3%80%8B/"/>
    <id>http://example.com/2021/08/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E3%80%8AREFORMER-THE-EFFICIENT-TRANSFORMER%E3%80%8B/</id>
    <published>2021-08-25T16:00:00.000Z</published>
    <updated>2021-08-26T16:46:27.178Z</updated>
    
    <content type="html"><![CDATA[<h2 id="summary">0. Summary</h2><p>reformer主要提出的Locality-sensitive hashing attention，根据attention的稀疏和softmax的最大元素支配性质只关心与query最近的K，通过Locality-sensitive hashing实现由query找key，但是受到Q=K的限制。还用到Reversible residual layer降低中间层的内存、以及feed forward层进行Chunking进一步降低显存。</p><span id="more"></span><h2 id="problem-statement">1. Problem Statement</h2><p>Reformer提出了Transformer中的三个问题。</p><ul><li>problem1: 注意力机制的计算需要<span class="math inline">\(O(L^2)\)</span>的时间和空间复杂度。</li><li>problem2: transformer的层数较多，而N层模型的内存消耗是单层模型的N倍，因为需要存储每一层中的激活以进行反向传播。链式法则<span class="math inline">\([g(f(x))]&#39;=g&#39;(f(x))*f&#39;(x)\)</span>。</li><li>problem3: 前馈层的维度通常比注意激活的维度大得多。<span class="math inline">\(d_{ff}&gt;d_{model}\)</span>。在一些模型中<span class="math inline">\(d_{ff}=4K\)</span>甚至更多，需要消耗大量显存。</li></ul><p>针对以上三个问题分别提出了三个解决方法：Locality-sensitive hashing attention、Reversible residual layer、Chunking。</p><h2 id="methods">2. Methods</h2><h3 id="locality-sensitive-hashing-attention">2.1 Locality-sensitive hashing attention</h3><p><strong>hasing attention</strong>：计算和存储全矩阵<span class="math inline">\(QK^T\)</span>是没有必要的，因为我们只对<span class="math inline">\(softmax(QK^T)\)</span>感兴趣，而softmax有最大元素支配的性质。所以对于<span class="math inline">\(q_i\)</span>我们只关心<span class="math inline">\(K\)</span>中与之最接近的前几个<span class="math inline">\(k\)</span>。 <span class="math display">\[\operatorname{Attention}(q_i, K, V)=\operatorname{softmax}\left(\frac{q_i K^{T}}{\sqrt{d_{k}}}\right) V\]</span> <strong>Locality-sensitive hashing</strong>：期望距离近的向量以较高的概率获得相同的散列。哈希大小为b,生成随机的矩阵<span class="math inline">\(R^{[d_k,b/2]}\)</span>。散列函数为<span class="math inline">\(h(x)=argmax([xR;-xR])\)</span></p><p><img src="https://i.bmp.ovh/imgs/2021/08/e3d78151097e7995.png" style="zoom:67%;" /></p><p><strong>LSH attention：</strong>对于LSH attention，Q=K，只需要计算Q和K矩阵的LSH散列，然后仅计算同一哈希桶中的k和q向量的标准关注度。</p><p><strong>LSH attention 流程</strong>：</p><ol type="1"><li>按照桶号对查询进行排序，桶内按照序列位置排序。</li><li>hash桶大小不相同，一个桶中的key和query的数量可能不一样，跨桶批处理困难。为了解决分配不均的问题，令<span class="math inline">\(k=\frac{q}{|q|}\)</span>，这样<span class="math inline">\(h(k)=h(q)\)</span>。论文中对常规的Transformer做了<span class="math inline">\(K = Q\)</span>的实验，证明不影响效果。<span class="math inline">\(K = Q\)</span>带来另一个问题就是通常会更注意自身，可以加一个mask屏蔽掉。</li><li>分块计算:令块的大小<span class="math inline">\(m=\frac{2l}{b}\)</span>，<span class="math inline">\(l\)</span>是序列长度，<span class="math inline">\(b\)</span>是桶的数量。在当前块与前一个块的并中计算权重。</li></ol><p><img src="https://i.bmp.ovh/imgs/2021/08/8e757dc5604f56ab.png" style="zoom:50%;" /></p><h3 id="reversible-residual-layer">2.2 Reversible residual layer</h3><p>reformer中：<span class="math inline">\(Y_1=X_1+Attention(X_2);Y_2=X_2+FeedForward(Y_1)\)</span>，使用可逆残差层而不是标准残差可以在训练过程中仅将激活存储一次，而不是N次。在反向传播时只使用模型参数就可以从下一层的激活结果中恢复任何给定层的激活结果，从而不用保存中间层的激活结果。</p><p><img src="https://s3.bmp.ovh/imgs/2021/08/0391d8362488a0ea.png" style="zoom:50%;" /></p><h3 id="chunking">2.3 Chunking</h3><p>比较厚的层仍会占用大量内存，前馈层的计算在序列中是完全独立的，所以可以分块处理，分chunk分开进行运算。 <span class="math display">\[Y_{2}=\left[Y_{2}^{(1)} ; \ldots ; Y_{2}^{(c)}\right]=\left[X_{2}^{(1)}+\text { FeedForward }\left(Y_{1}^{(1)}\right) ; \ldots ; X_{2}^{(c)}+\text { FeedForward }\left(Y_{1}^{(c)}\right)\right] \]</span></p><h2 id="evaluation">3. Evaluation</h2><p>Shared-QK效果：从下图实验结果可以看出共享QK机制并没有比标准注意力机制效果差。</p><p><img src="https://s3.bmp.ovh/imgs/2021/08/5a8790a42251d1c0.png" /></p><p>可逆层的效果：这里还是用标准Transformer跟可逆网络层对比，二者所使用的参数基本一样，学习曲线图如上：二者曲线基本一致，这说明可逆网络结构在节省内存的前提下，并没有损伤精度。</p><p><img src="https://s3.bmp.ovh/imgs/2021/08/64ace73cb7182c24.png" /></p><p>LSH attention in Transformer：相比全注意力机制，LSH注意力是一个近似的方法，从下面的实验图可以看出随着hash函数的增加，精确度也越来越高。在nrounds = 8的时候，精确度已经跟全注意力机制相匹敌了；但是hash函数越多，计算代价就越高，所以这个超参数可以根据实际计算资源进行调整。</p><p><img src="https://s3.bmp.ovh/imgs/2021/08/f48fcceb6dbe2ba0.png" /></p><p>不同注意力机制的速度：可以看出，随着序列长度的不断增加，标准注意力机制变得越来越慢，而LSH注意力机制基本变化不大，提速效果非常明显。</p><p><img src="https://s3.bmp.ovh/imgs/2021/08/c0d6491f9b0f20ba.png" /></p><h2 id="conclusion">4. Conclusion</h2><p>Reformer 针对 Transformer 中的三个问题提出了三个解决方法Locality-sensitive hashing attention、Reversible residual layer、Chunking，在与 Transformer 模型的性能相当的情况下，降低了在长序列任务下的时间与空间复杂度。</p><h2 id="notes">5. Notes</h2><p>Trax：实现了reformer的过程可以学习<a href="https://github.com/google/trax/tree/master/trax/models/reformer">code</a></p><p>Transformers也对reformer进行了实现<a href="https://github.com/huggingface/transformers">code</a>。</p><h2 id="reference">Reference</h2><p>[1] Kitaev N, Kaiser Ł, Levskaya A. Reformer: The efficient transformer[J]. arXiv preprint arXiv:2001.04451, 2020.</p><p>[2] Vaswani A, Shazeer N, Parmar N, et al. Attention is all you need[C]//Advances in neural information processing systems. 2017: 5998-6008.</p><p>[3] Beltagy I, Peters M E, Cohan A. Longformer: The long-document transformer[J]. arXiv preprint arXiv:2004.05150, 2020.</p><p>[4] <a href="https://towardsdatascience.com/illustrating-the-reformer-393575ac6ba0">💡Illustrating the Reformer. 🚊 ️ The efficient Transformer | by Alireza Dirafzoon | Towards Data Science</a></p><p>[5] <a href="http://jalammar.github.io/illustrated-transformer/">The Illustrated Transformer – Jay Alammar – Visualizing machine learning one concept at a time. (jalammar.github.io)</a></p><p>[6] <a href="https://github.com/huggingface/transformers">huggingface/transformers: 🤗 Transformers: State-of-the-art Natural Language Processing for Pytorch, TensorFlow, and JAX. (github.com)</a></p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;summary&quot;&gt;0. Summary&lt;/h2&gt;
&lt;p&gt;reformer主要提出的Locality-sensitive hashing attention，根据attention的稀疏和softmax的最大元素支配性质只关心与query最近的K，通过Locality-sensitive hashing实现由query找key，但是受到Q=K的限制。还用到Reversible residual layer降低中间层的内存、以及feed forward层进行Chunking进一步降低显存。&lt;/p&gt;</summary>
    
    
    
    <category term="论文阅读" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
    
    <category term="学习笔记" scheme="http://example.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>Lec01 课程简介及算法分析</title>
    <link href="http://example.com/2021/03/28/Lec01%E8%AF%BE%E7%A8%8B%E7%AE%80%E4%BB%8B%E5%8F%8A%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/"/>
    <id>http://example.com/2021/03/28/Lec01%E8%AF%BE%E7%A8%8B%E7%AE%80%E4%BB%8B%E5%8F%8A%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/</id>
    <published>2021-03-28T16:00:00.000Z</published>
    <updated>2021-08-26T16:16:12.359Z</updated>
    
    <content type="html"><![CDATA[<p>MIT算法导论课程：Lec01 简介及算法分析，对应书上的章节：Chapters 1-2。</p><span id="more"></span><h2 id="介绍">1.介绍</h2><h3 id="先修课程">1.1 先修课程</h3><p>离散数学、概率论、编程课程</p><h3 id="算法分析">1.2 算法分析</h3><p>计算机程序性能和资源使用的理论研究（尤其关注性能）。</p><h3 id="比性能更重要的因素">1.3 比性能更重要的因素</h3><p>比如有正确性、简洁性、可维护性、编程成本、稳定性、功能性、模块化、安全性、可扩展性、用户友好度等。</p><h3 id="算法的重要性">1.4 算法的重要性</h3><ul><li>算法将不可行变为可行。</li><li>算法是一种描述程序行为的语言。</li></ul><h2 id="排序问题">2. 排序问题</h2><h3 id="insertion-sort">2.1 Insertion sort</h3><p><strong>伪代码（pseudocode）</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">for j ← 2 to n</span><br><span class="line">    do key ← A[j]</span><br><span class="line">    i ← j-1</span><br><span class="line">    while i &gt; 0 and A[i] &gt;key</span><br><span class="line">        do A[i+1] ← A[i]</span><br><span class="line">        i ← i-1</span><br><span class="line">    A[i+1] ← key</span><br></pre></td></tr></table></figure><p><strong>运行时间（Running time）</strong></p><ul><li>取决于数据，有序的数据速度更快。</li><li>取决于数据规模大小。</li><li>更关注运行时间的上限，更有保证。</li></ul><p><strong>分析方法（Kinds of analyses）</strong></p><ul><li>最坏情况：取决于计算机性能，通常描述不使用绝对速度，关注相对速度。</li><li>平均情况：需要假设数据分布</li><li>最好情况：有迷惑性</li><li>渐近分析（Asymptotic Analysis）<ul><li><span class="math inline">\(\Theta(g(n))={f(n):存在正的常数c_1,c_2已经n_0使得对于所有的n&gt;=n_0都有0\leq c_1g(n)\leq f(n)\leq c_2g(n)}\)</span>，也就是去掉函数的低阶项和最高阶项系数。</li><li>关注随模型增长的增长情况</li></ul></li></ul><h3 id="merge-sort">2.2 Merge Sort</h3><p><strong>伪代码</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">MERGE-SORT A[1...n]</span><br><span class="line">1.if n&#x3D;1,done</span><br><span class="line">2.recursively sort A[1..[n&#x2F;2]] and A[[n&#x2F;2]+1,...,n]</span><br><span class="line">3.merge 2 sorted lists</span><br></pre></td></tr></table></figure><p><strong>算法分析</strong></p><p><span class="math inline">\(T(n)=2(T/2)+\Theta(n)\)</span></p><p><span class="math inline">\(T(n)=2(T/2)+c n\)</span></p><p><strong>递归树 Recursion tree</strong></p><p><img src="https://ftp.bmp.ovh/imgs/2021/03/20e766da834288c8.png" style="zoom:67%;" /></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;MIT算法导论课程：Lec01 简介及算法分析，对应书上的章节：Chapters 1-2。&lt;/p&gt;</summary>
    
    
    
    <category term="算法导论MIT" scheme="http://example.com/categories/%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BAMIT/"/>
    
    
    <category term="学习笔记" scheme="http://example.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>Lec02 渐进符号、递归及解法</title>
    <link href="http://example.com/2021/03/28/Lec02%E6%B8%90%E8%BF%9B%E7%AC%A6%E5%8F%B7%E5%92%8C%E9%80%92%E5%BD%92%E5%8F%8A%E8%A7%A3%E6%B3%95/"/>
    <id>http://example.com/2021/03/28/Lec02%E6%B8%90%E8%BF%9B%E7%AC%A6%E5%8F%B7%E5%92%8C%E9%80%92%E5%BD%92%E5%8F%8A%E8%A7%A3%E6%B3%95/</id>
    <published>2021-03-28T16:00:00.000Z</published>
    <updated>2021-03-28T18:23:47.893Z</updated>
    
    <content type="html"><![CDATA[<p>MIT算法导论课程：Lec02 渐进符号、递归及解法，对应书的章节：Chapters 3-4, excluding section 4.6。</p><span id="more"></span><h2 id="渐进符号asymptotic-notation">1. 渐进符号（Asymptotic Notation）</h2><h3 id="o-notation-upper-bounds">1.1 <span class="math inline">\(O\)</span>-notation （upper bounds）</h3><p><span class="math inline">\(f(n)=O(g(n))\)</span> 如果存在常量<span class="math inline">\(c&gt;0,n_0&gt;0\)</span>对所有的<span class="math inline">\(n\geq n_0\)</span>都有<span class="math inline">\(0\leq f(n)\leq cg(n)\)</span>。</p><p>比如 <span class="math inline">\(2n^2=O(n^3)\)</span>，这个符号可以用<span class="math inline">\(\leq\)</span>理解，表示<span class="math inline">\(g(n)\)</span>是<span class="math inline">\(f(n)\)</span>的上界。</p><h3 id="omega-notationlower-bounds">1.2 <span class="math inline">\(\Omega\)</span>-notation（lower bounds）</h3><p><span class="math inline">\(f(n)=\Omega(g(n))\)</span> 如果存在常量<span class="math inline">\(c&gt;0,n_0&gt;0\)</span>对所有的<span class="math inline">\(n\geq n_0\)</span>都有$0cg(n) f(n) $。</p><p>比如 <span class="math inline">\(\sqrt n=\Omega(\lg n)\)</span>，这个符号可以用<span class="math inline">\(\geq\)</span>理解，表示下界。</p><h3 id="theta-notationtight-bounds">1.3 <span class="math inline">\(\Theta\)</span>-notation（tight bounds）</h3><p><span class="math inline">\(\Theta(g(n))=O(g(n))\cap \Omega(g(n))\)</span></p><p>比如<span class="math inline">\(\frac{1}{2}n^2-2n=\Omega(n^2)\)</span>，可以用<span class="math inline">\(=\)</span>理解。</p><h3 id="o-notation">1.4 <span class="math inline">\(o\)</span>-notation</h3><p><span class="math inline">\(f(n)=o(g(n))\)</span> 如果存在常量<span class="math inline">\(c&gt;0,n_0&gt;0\)</span>对所有的<span class="math inline">\(n\geq n_0\)</span>都有<span class="math inline">\(0\leq f(n)&lt; cg(n)\)</span>。</p><p>比如<span class="math inline">\(2n^2=o(n^3)\)</span>，可以用&lt;理解。</p><h3 id="omega-notation">1.5 <span class="math inline">\(\omega\)</span>-notation</h3><p><span class="math inline">\(f(n)=\omega(g(n))\)</span> 如果存在常量<span class="math inline">\(c&gt;0,n_0&gt;0\)</span>对所有的<span class="math inline">\(n\geq n_0\)</span>都有$0cg(n) &lt; f(n) $。</p><p>比如<span class="math inline">\(\sqrt n=\omega(\lg n)\)</span>，可以用&gt;理解。</p><h2 id="递归recurrences">2. 递归（Recurrences）</h2><h3 id="代换法substitution-method">2.1 代换法（Substitution method）</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. Guess 猜测结果。</span><br><span class="line">2. verify 归纳验证。</span><br><span class="line">3. solve 求系数。</span><br></pre></td></tr></table></figure><p>例子：<span class="math inline">\(T(n)=4T(n/2)+n;T(1)=\Theta(1)\)</span></p><p>（一）假设<span class="math inline">\(T(n)=O(n^3)\)</span></p><ol type="1"><li><p>假设<span class="math inline">\(T(n)=O(n^3)\)</span> 则<span class="math inline">\(T(k)\leq ck^3\)</span> for <span class="math inline">\(k&lt;n\)</span></p></li><li><span class="math inline">\(T(n)=4T(n/2)+n\leq4c(n/2)^3+n=cn^3-((cn^3)/2-n)\)</span> 构造成 desired-residual，就是假设的减去剩下的。</li><li>要使得假设成立，则<span class="math inline">\(cn^3/2-n\geq0\)</span>，所以<span class="math inline">\(c\geq2，n\geq1\)</span>不等式成立。</li><li><p>我们还必须处理初始条件，<span class="math inline">\(T(1)=\Theta(1)\leq c*1^3\)</span>，当c取足够大的数时不等式成立。（This bound is not tight!）</p></li></ol><p>（二）假设<span class="math inline">\(T(n)=O(n^2)\)</span></p><ol type="1"><li>假设<span class="math inline">\(T(n)=O(n^2)\)</span> 则<span class="math inline">\(T(k)\leq ck^2\)</span> for <span class="math inline">\(k&lt;n\)</span></li><li><span class="math inline">\(T(n)=4T(n/2)+n\leq4c(n/2)^2+n=c*n^2-(-n)\)</span></li><li>要使假设成立需要<span class="math inline">\(-n&gt;0\)</span>，不能成立</li></ol><p>（三）加强归纳假设</p><ol type="1"><li>假设<span class="math inline">\(T(n)=O(n^2)\)</span> 则<span class="math inline">\(T(k)\leq c_1k^2-c_2k\)</span> for <span class="math inline">\(k&lt;n\)</span></li><li><span class="math inline">\(T(n)=4T(n/2)+n\leq c_1n^2-c_2n\)</span></li><li>要使假设成立，<span class="math inline">\(c_2\geq 1\)</span></li><li>验证初始条件<span class="math inline">\(T(1)=\Theta(1)\leq c_1*1^2-c_2*1\)</span>，<span class="math inline">\(c_1\)</span>足够大不等式成立。</li></ol><p>求<span class="math inline">\(T(n)\)</span>的下界用类似的方法。</p><h3 id="递归树方法recursion-tree-method">2.2 递归树方法（Recursion-tree method）</h3><p>这个方法不够严谨，比较好的解题过程应该是用递归树法求出结果后再用代换法验证。</p><p><img src="https://ftp.bmp.ovh/imgs/2021/01/33bc3bf17a284dc8.png" style="zoom: 50%;" /></p><h3 id="主方法the-master-method">2.3 主方法（The master method）</h3><p>主方法解决形如<span class="math inline">\(T(n)=aT(n/b)+f(n)\)</span>的式子，并且<span class="math inline">\(a\geq1,b\geq1\)</span>，<span class="math inline">\(f(n)\)</span>是趋近为正的。</p><ol type="1"><li><strong>case1：</strong><span class="math inline">\(f(n)=O(n^{\log_ba-\epsilon}),\epsilon&gt;0\)</span>，<span class="math inline">\(f(n)\)</span> 比<span class="math inline">\(n^{\log_ba}\)</span>的增长慢<span class="math inline">\(n^\epsilon\)</span>多项式级，<strong>Solution：</strong> <span class="math inline">\(T(n)=\Theta(n^{log_ba})\)</span></li><li><strong>case2：</strong> <span class="math inline">\(f(n)=\Theta(n^{\log_ba}\lg^kn),k\geq 0\)</span> <span class="math inline">\(f(n)\)</span>和<span class="math inline">\(n^{log_ba}\)</span>有一样的增长速度，<strong>Solution:</strong><span class="math inline">\(T(n)=\Theta(n^{\log_ba}\lg^{k+1}n)\)</span></li><li><strong>case3：</strong> <span class="math inline">\(f(n)=\Omega(n^{\log_ba+\epsilon}),\epsilon&gt;0\)</span>，并且存在<span class="math inline">\(c&lt;1,af(n/b)\leq cf(n)\)</span> <span class="math inline">\(f(n)\)</span> 比<span class="math inline">\(n^{\log_ba}\)</span>的增长快<span class="math inline">\(n^\epsilon\)</span>多项式级，<strong>solution：</strong> <span class="math inline">\(T(n)=\Theta(f(n))\)</span></li></ol><p><strong>用递归树来理解主方法</strong></p><p><strong>case1:</strong></p><p><img src="https://ftp.bmp.ovh/imgs/2021/01/d96bb64eef94c195.png" style="zoom:50%;" /></p><p><strong>case2：</strong></p><p><img src="https://ftp.bmp.ovh/imgs/2021/01/48ae662c70a10496.png" style="zoom:50%;" /></p><p><strong>case3：</strong></p><p><img src="https://ftp.bmp.ovh/imgs/2021/01/d9e63987e5069e08.png" style="zoom:50%;" /></p><h2 id="appendix-geometric-series">Appendix: geometric series</h2><p><span class="math display">\[\begin{array}{c}1+x+x^{2}+\cdots+x^{n}=\frac{1-x^{n+1}}{1-x} \text { for } x \neq 1 \\1+x+x^{2}+\cdots=\frac{1}{1-x} \quad \text { for }|x|&lt;1\end{array}\]</span></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;MIT算法导论课程：Lec02 渐进符号、递归及解法，对应书的章节：Chapters 3-4, excluding section 4.6。&lt;/p&gt;</summary>
    
    
    
    <category term="算法导论MIT" scheme="http://example.com/categories/%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BAMIT/"/>
    
    
    <category term="学习笔记" scheme="http://example.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>Lec12跳跃表</title>
    <link href="http://example.com/2021/03/28/Lec12%E8%B7%B3%E8%B7%83%E8%A1%A8/"/>
    <id>http://example.com/2021/03/28/Lec12%E8%B7%B3%E8%B7%83%E8%A1%A8/</id>
    <published>2021-03-28T08:14:58.000Z</published>
    <updated>2021-03-29T00:23:20.307Z</updated>
    
    <content type="html"><![CDATA[<p>MIT算法导论课程：Lec12跳跃表。</p><span id="more"></span><h2 id="skip-lists">1. Skip Lists</h2><p>跳跃表：随机化动态搜索结构，简单容易实现。<span class="math inline">\(O(\lg n)\)</span>的期望运行时间， 并且有很大的概率<span class="math inline">\(1-\frac{1}{e^\alpha}\)</span>。</p><p>其他高效的动态搜索结构，比如树堆、红黑树、B-trees。</p><p><strong>sorted linked list</strong></p><p>search:<span class="math inline">\(\Theta(n)\)</span> time，如何提速呢？</p><p><strong>Two linked list</strong></p><p>IDEA：新加一个list来作为“快速通道”。</p><p><img src="https://i.bmp.ovh/imgs/2021/03/5c89bcbbdc1a8ea5.png" style="zoom:50%;" /></p><p>search(x)</p><ol type="1"><li>从list L1向右搜索，直到搜索过头</li><li>向下到list L2</li><li>向右搜索，直到搜索到元素</li></ol><p><strong>Analysis</strong></p><p>粗略估计：<span class="math inline">\(|L1|+\frac{|L2|}{|L1|}\)</span>. <span class="math inline">\(|L2|=n\)</span></p><p>最小化： <span class="math inline">\(|L1|=\sqrt n\)</span></p><p>2 sort lists: <span class="math inline">\(2 \sqrt n\)</span></p><p>3 sort lists: <span class="math inline">\(3n^{1/3}\)</span></p><p>k sorted lists: <span class="math inline">\(kn^{1/k}\)</span></p><p><span class="math inline">\(\lg n\)</span> sorted lists:<span class="math inline">\(\lg n*n^{1/\lg n}=2\lg n\)</span></p><p><span class="math inline">\(\lg n\)</span> sorted lists 像一个二分树。</p><p><strong>Ideal skip list</strong> is this <span class="math inline">\(\lg n\)</span> linked list structure.</p><p>上一次与下一层的比为1:2，负无穷存在所有表中的最左边。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">INSERT(x)</span><br><span class="line">最底层插入的有所有元素。以1&#x2F;2的概率决定下一层是否插入。</span><br><span class="line"></span><br><span class="line">DELETE(x)</span><br><span class="line">删除所有表中的x</span><br></pre></td></tr></table></figure><p><img src="https://i.bmp.ovh/imgs/2021/03/614985fbff593b99.png" style="zoom:50%;" /></p><p>不仅平均为<span class="math inline">\(O(\lg n)\)</span>，并且高概率为<span class="math inline">\(O(\lg n)\)</span></p><h2 id="with-high-probability-theorem">2. With-high-probability theorem</h2><p><strong>THEOREM:</strong> 有很高的概率，每次搜索的时间消耗是<span class="math inline">\(O(\lg n)\)</span></p><p><strong>Boole’s inequality</strong></p><p><img src="https://i.bmp.ovh/imgs/2021/03/0aa140691c4a2ad3.png" style="zoom:50%;" /></p><p>如果<span class="math inline">\(k=n^{O(1)}\)</span>，每一个<span class="math inline">\(E_i\)</span>都具有高概率，那么<span class="math inline">\(E_1 \cap E_2,...,\cap E_k\)</span>.</p><p><img src="https://i.bmp.ovh/imgs/2021/03/c19ba3e532edd693.png" style="zoom:67%;" /></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;MIT算法导论课程：Lec12跳跃表。&lt;/p&gt;</summary>
    
    
    
    <category term="算法导论MIT" scheme="http://example.com/categories/%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BAMIT/"/>
    
    
    <category term="学习笔记" scheme="http://example.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>Lec14 竞争性分析，自组织表</title>
    <link href="http://example.com/2021/03/28/Lec14%E7%AB%9E%E4%BA%89%E6%80%A7%E5%88%86%E6%9E%90%EF%BC%8C%E8%87%AA%E7%BB%84%E7%BB%87%E8%A1%A8/"/>
    <id>http://example.com/2021/03/28/Lec14%E7%AB%9E%E4%BA%89%E6%80%A7%E5%88%86%E6%9E%90%EF%BC%8C%E8%87%AA%E7%BB%84%E7%BB%87%E8%A1%A8/</id>
    <published>2021-03-28T08:14:58.000Z</published>
    <updated>2021-03-29T00:40:29.468Z</updated>
    
    <content type="html"><![CDATA[<p>MIT算法导论课程：Lec14 竞争性分析，自组织表，对应Sleator, Daniel D., and Robert E. Tarjan. &quot;Amortized efficiency of list update and paging rules.&quot; Communications of the ACM 28, no. 2 (February 1985): 202-208.</p><span id="more"></span><h2 id="self-organizing-lists">1. Self-organizing lists</h2><p><strong>Self-organizing lists</strong></p><p>表<code>L</code>有<code>n</code>个元素，操作<code>ACCESS(x)</code>的成本为<span class="math inline">\(rank_L(x)\)</span>，也就是x到头节点的长度。L可以相邻元素的交换，cost为1.</p><p><strong>On-line and off-line problems</strong></p><p>on-line：序列操作<code>S</code>,必须立刻执行操作，不知道未来的操作。</p><p>off-line：可以提前看到之后所有的操作。</p><p>Goal：最小化总成本<span class="math inline">\(C_A(S)\)</span>。</p><p><strong>Worst-case analysis of self organizing lists</strong></p><p>worst case：总是访问L中的尾元素，<span class="math inline">\(C_A(S)=\Omega(|S|*n)\)</span>。</p><p><strong>Average-case analysis of self organizing lists</strong></p><p>假设元素<code>x</code>以概率<code>p(x)</code>被访问，<span class="math inline">\(E[C_A(S)]=\sum_{x\in L}p(x)*rank_L(x)\)</span>。其中当<code>L</code>以概率<code>P</code>降序进行排序时期望成本最小。</p><p>Heuristic:对访问的元素进行计数，然后保存<code>L</code>以计数降序排序。</p><h2 id="move-to-front-heuristic">2. Move-to-front heuristic</h2><p>在实践中发现move-to-front(MTF)启发式的方法有较好的结果。具体做法是在访问<code>x</code>后，将<code>x</code>移动到表头，<span class="math inline">\(cost=2*rank_L(x)\)</span>。MTF方法对于局部性方法有较好的解。</p><h2 id="competitive-analysis-of-mtf">3. Competitive analysis of MTF</h2><p><strong>定义：</strong> 一个on-line算法A是<span class="math inline">\(\alpha-competitive\)</span> 如果存在常数<code>k</code>对于任何操作序列<code>S</code>有<span class="math inline">\(C_A(S)\leq \alpha*C_{OPT}(S)+k\)</span>，其中<span class="math inline">\(OPT\)</span>是off-line的最优算法。</p><p><strong>Theorem：</strong> MTF对于self-organizing lists是一个4-competitive。</p><p><strong>proof：</strong></p><p>首先定义一些变量：</p><p><img src="https://i.bmp.ovh/imgs/2021/03/8d09cdd9f9cd4ce6.png" style="zoom:67%;" /></p><p>定义势能函数<span class="math inline">\(\Phi:{L_i}-&gt;R\)</span> <span class="math display">\[\begin{aligned}&amp;\Phi\left(L_{i}\right)=2 \cdot \mid\left\{(x, y): x \prec_{L_{i}} y \text { and } y \prec_{L_{i} *} x\right\}\\&amp;=2 \cdot \# \text { inversions }\end{aligned}\]</span> <img src="https://i.bmp.ovh/imgs/2021/03/6b13e6ead2c33c68.png" style="zoom:67%;" /></p><p>可以看出：</p><ul><li><span class="math inline">\(\Phi(L_i)\geq 0\)</span> for all i&gt;=0</li><li><span class="math inline">\(\Phi(L_0)=0\)</span> 如果MTF和OPT开始时一样</li></ul><p>一次transpose，<span class="math inline">\(\Delta\Phi=\pm2\)</span>，因为一次transpose会产生或者消除一个逆序对。</p><p>下面看当访问一个元素会发生什么，进行如下的定义：</p><p><img src="https://i.bmp.ovh/imgs/2021/03/3de2caa7c0a77734.png" style="zoom:67%;" /></p><p><span class="math inline">\(r=rank_{i-1}(x)=|A|+|B|+1\)</span>，<span class="math inline">\(r^*=|A|+|C|+1\)</span>.</p><p>MTF将x移动到表头，产生|A|的逆序对，消除了|B|的逆序。对OPT的每次transpose产生小于1的逆序对，因此<span class="math inline">\(\Phi(L_i)-\Phi(L_{i-1}\leq2(|A|-|B|+t_i))\)</span>.</p><p><strong>Amortized cost</strong></p><p>MTF第<code>i</code>次操作的平摊代价为： <span class="math display">\[\begin{aligned}\hat{c}_{i} &amp;=c_{i}+\Phi\left(L_{i}\right)-\Phi\left(L_{i-1}\right) \\&amp; \leq 2 r+2\left(|A|-|B|+t_{i}\right) \\&amp;=2 r+2\left(|A|-(r-1-|A|)+t_{i}\right) \\&amp;=2 r+4|A|-2 r+2+2 t_{i} \\&amp;=4|A|+2+2 t_{i} \\&amp; \leq 4\left(r^{*}+t_{i}\right) \\&amp;=4 c_{i}^{*}\end{aligned}\]</span></p><p>因此我们可以得出：</p><p><span class="math display">\[\begin{aligned}C_{\mathrm{MTF}}(S) &amp;=\sum_{i=1}^{|S|} c_{i} \\&amp;=\sum_{i=1}^{|S|}\left(\hat{c}_{i}+\Phi\left(L_{i-1}\right)-\Phi\left(L_{i}\right)\right) \\&amp; \leq\left(\sum_{i=1}^{|S|} 4 c_{i}^{*}\right)+\Phi\left(L_{0}\right)-\Phi\left(L_{|S|}\right) \\&amp; \leq 4 \cdot C_{\mathrm{OPT}}(S)\end{aligned}\]</span> <strong>Addendum</strong></p><p>如果将把<code>x</code>转移到表头的代价看作0（x从表中拆除在插在表头，时间是常量），则MTF是2-competitive。</p><p>如果<span class="math inline">\(L_0\neq L_0^*\)</span></p><ul><li><span class="math inline">\(\Phi(L_0)\)</span>最差情况为<span class="math inline">\(\Theta(n^2)\)</span>。</li><li>因此：<span class="math inline">\(C_{MTF}\leq 4*C_{OPT}(S)+\Theta(n^2)\)</span>，也是4-competitive，因为<span class="math inline">\(|S|-&gt;+\infty\)</span>，<span class="math inline">\(n^2\)</span>也是常量，n不受到|S|的影响。</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;MIT算法导论课程：Lec14 竞争性分析，自组织表，对应Sleator, Daniel D., and Robert E. Tarjan. &amp;quot;Amortized efficiency of list update and paging rules.&amp;quot; Communications of the ACM 28, no. 2 (February 1985): 202-208.&lt;/p&gt;</summary>
    
    
    
    <category term="算法导论MIT" scheme="http://example.com/categories/%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BAMIT/"/>
    
    
    <category term="学习笔记" scheme="http://example.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>Lec13 平摊分析，表的扩增，势能方法</title>
    <link href="http://example.com/2021/03/28/Lec13%E5%B9%B3%E6%91%8A%E5%88%86%E6%9E%90%E3%80%81%E8%A1%A8%E7%9A%84%E6%89%A9%E5%A2%9E%E3%80%81%E5%8A%BF%E8%83%BD%E6%96%B9%E6%B3%95/"/>
    <id>http://example.com/2021/03/28/Lec13%E5%B9%B3%E6%91%8A%E5%88%86%E6%9E%90%E3%80%81%E8%A1%A8%E7%9A%84%E6%89%A9%E5%A2%9E%E3%80%81%E5%8A%BF%E8%83%BD%E6%96%B9%E6%B3%95/</id>
    <published>2021-03-28T08:14:58.000Z</published>
    <updated>2021-03-29T00:33:03.197Z</updated>
    
    <content type="html"><![CDATA[<p>MIT算法导论课程：Lec13 平摊分析，表的扩增，势能方法，对应书上的章节：Chapter 17</p><p>平摊分析（Amortized Analysis）</p><span id="more"></span><h2 id="dynamic-tables">1. Dynamic tables</h2><p>一个哈希表多大合适？我们知道越大搜索时间越小，但越大浪费空间越多。比较好的大小为<span class="math inline">\(\Theta(n)\)</span>。但如果n是未知的呢？这时可以用动态表解决，动态表的思想是当表溢出时，增大表的大小，就像malloc或new申请一个新的表，然后将旧表的项移动到新表。</p><p><strong>Worst-case analysis</strong></p><p>考虑一个有n个插入操作的序列，在最坏情况下的时间为<span class="math inline">\(n*\Theta(n)=\Theta(n^2)\)</span>，<strong>WRONG!</strong>，因为不是所有操作都是最坏情况。</p><p>定义一个<span class="math inline">\(c_i\)</span>代表第<code>i</code>次插入的代价，<span class="math inline">\(=\left\{\begin{array}{ll} i &amp; \text { if } i-1 \text { is an exact power of } 2 \\ 1 &amp; \text { otherwise } \end{array}\right.\)</span>，表每次扩2倍大。在2的power时进行扩大，代价为<code>i</code>。其他情况下cost为<code>1</code>。 <span class="math display">\[\begin{aligned}\text { Cost of } n \text { insertions } &amp;=\sum_{i=1}^{n} c_{i} \\&amp; \leq n+\sum_{j=0}^{\lfloor\lg (n-1)\rfloor} 2^{j} \\&amp; \leq 3 n \\&amp;=\Theta(n)\end{aligned}\]</span> 因此，dynamic-table操作的平均时间为<span class="math inline">\(\Theta(n)/n=\Theta(1)\)</span>.</p><p><strong>Amortized analysis</strong></p><p>这种分析方法即为平摊分析（Amortized Analysis），用于分析序列操作，然后分摊到每个操作去。没有用的概率，平摊分析可确保在最坏的情况下每个操作的平均性能。</p><p><strong>Types of amortized analyses</strong></p><p>有三种方法：</p><ul><li><p>the aggregate method，</p></li><li>the accounting method,</li><li><p>the potential method</p></li></ul><h2 id="aggregate-method">2. Aggregate method</h2><p>刚刚介绍的是the aggregate method，比较简单。但是其他两种方法允许将特定的摊销成本分配给每个操作。</p><h2 id="accounting-method">3. Accounting method</h2><p>对第<code>i</code>个操作收取一个费用<span class="math inline">\(\hat c_i\)</span>，一个元操作收取一元，执行此操作将消耗此费用。任何未立即消耗的金额都存储在银行中，以供后续操作使用。银行余额不得为负！我们必须确保对于所有的n:<span class="math inline">\(\sum_{i=1}^{n} c_{i} \leq \sum_{i=1}^{n} \hat{c}_{i}\)</span>.因此，总摊销成本为总真实成本提供了一个上限。</p><p><strong>例子</strong></p><p>对<span class="math inline">\(\hat c_i=\$3\)</span>，1个用来支付插入操作，2个用来存入银行。当表扩大的时候，1个钱用来移动一个项。</p><p>银行余额永远不会低于0。因此，摊销成本的总和为真实成本的总和提供了一个上限。</p><p><img src="https://i.bmp.ovh/imgs/2021/03/b6357b14e88b4ae0.png" style="zoom:50%;" /></p><h2 id="potential-method">4. Potential method</h2><p><strong>IDEA：</strong> 将银行帐户视为动态集的势能（按物理原理）</p><p><strong>Framework:</strong></p><ol type="1"><li><p>从初始数据结构<span class="math inline">\(D_0\)</span>开始</p></li><li><p>操作<code>i</code>将<span class="math inline">\(D_{i-1}\)</span>转化为<span class="math inline">\(D_i\)</span>.</p></li><li><p>操作<code>i</code>的cost为<span class="math inline">\(c_i\)</span>.</p></li><li><p>定义势能函数<span class="math inline">\(\Phi :{D_i}-&gt;R,\Phi(D_0)=0 ,\Phi(D_i)&gt;=0\)</span>,</p></li><li><p>平摊代价 <span class="math inline">\(\hat c_i=c_i+\Phi(D_i)-\Phi(D_{i-1})\)</span></p></li></ol><p><img src="https://i.bmp.ovh/imgs/2021/03/7c5c42c3c849922d.png" style="zoom:67%;" /></p><p>n个操作的总平摊成本：<span class="math inline">\(\sum_{i=1}^{n} \hat{c}_{i}=\sum_{i=1}^{n}\left(c_{i}+\Phi\left(D_{i}\right)-\Phi\left(D_{i-1}\right)\right)=\sum_{i=1}^{n}c_i+\Phi(D_n)-\Phi(D_0)\geq \sum_{i=1}^{n} c_i\)</span></p><p><strong>Potential analysis of table doubling</strong></p><p>第<code>i</code>次插入后的势能，定义<span class="math inline">\(\Phi(D_i)=2i-2^{\lceil \lg i \rceil}\)</span>，假设<span class="math inline">\(2^{\lceil \lg i \rceil}=0\)</span></p><p><img src="https://i.bmp.ovh/imgs/2021/03/0be4cc3450eebf77.png" style="zoom: 67%;" /></p><p><img src="https://i.bmp.ovh/imgs/2021/03/6168d499c3f1b09f.png" /></p><p><img src="https://i.bmp.ovh/imgs/2021/03/1c09e78db4040c56.png" /></p><h2 id="小结">5. 小结</h2><ul><li>摊销成本可以提供数据结构性能的清晰抽象。</li><li>当需要进行摊销分析时，可以使用任何一种分析方法，但是每种方法在某些情况下都可以说是最简单或最精确的。</li><li>在accounting方法中分配摊余成本的方法可能不同，在potential方法中分配潜力的方法也可能不同，有时会产生根本不同的界限。</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;MIT算法导论课程：Lec13 平摊分析，表的扩增，势能方法，对应书上的章节：Chapter 17&lt;/p&gt;
&lt;p&gt;平摊分析（Amortized Analysis）&lt;/p&gt;</summary>
    
    
    
    <category term="算法导论MIT" scheme="http://example.com/categories/%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BAMIT/"/>
    
    
    <category term="学习笔记" scheme="http://example.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>Lec16 贪婪算法，最小生成树</title>
    <link href="http://example.com/2021/03/28/Lec16%E8%B4%AA%E5%A9%AA%E7%AE%97%E6%B3%95%EF%BC%8C%E6%9C%80%E5%B0%8F%E7%94%9F%E6%88%90%E6%A0%91/"/>
    <id>http://example.com/2021/03/28/Lec16%E8%B4%AA%E5%A9%AA%E7%AE%97%E6%B3%95%EF%BC%8C%E6%9C%80%E5%B0%8F%E7%94%9F%E6%88%90%E6%A0%91/</id>
    <published>2021-03-28T08:14:58.000Z</published>
    <updated>2021-03-29T00:35:46.870Z</updated>
    
    <content type="html"><![CDATA[<p>MIT算法导论课程：Lec16 贪婪算法，最小生成树，对应书上的章节：16.1-16.3 and 22.1, Chapter 23</p><span id="more"></span><h2 id="graph-representation">1. Graph representation</h2><p><strong>Graphs</strong></p><p>图分为有向图和无向图，可以用<span class="math inline">\(G=(V,E)\)</span>表示。</p><p><span class="math inline">\(|E|=O(V^2)\)</span>，又因为图是联通的，所以<span class="math inline">\(|E|\geq|V|-1\)</span>，因此<span class="math inline">\(\lg |E|=\Theta(\lg V)\)</span>.</p><p><strong>Adjacency-matrix representation</strong></p><p><img src="https://i.bmp.ovh/imgs/2021/03/4e68a733a02b513e.png" style="zoom:50%;" /></p><p>也可以用权重。<span class="math inline">\(\Theta(V^2)\)</span> storage，dense representation。</p><p><strong>Adjacency-list representation</strong></p><p>用表<span class="math inline">\(Adj[v]\)</span>表示<code>v</code>点指向的节点。</p><p>对于无向图：<span class="math inline">\(|Adj[v]|=degree(v)\)</span>.</p><p>对于有向图：<span class="math inline">\(|Adj[v]|=out-degree(v)\)</span>.</p><p>Handshaking Lemma:对于无向图<span class="math inline">\(\sum degree(v)=2|E|\)</span></p><p>所以Adjacency list是一个sparse representation，<span class="math inline">\(\Theta(V+E)\)</span>，经常比邻接矩阵要好。</p><h2 id="minimum-spanning-trees">2. Minimum spanning trees</h2><p>输入：一个联通无向图<span class="math inline">\(G=(V,E)\)</span>，和权重函数<span class="math inline">\(w:E-&gt;\R\)</span>。为了简化，所有边都是互异的。</p><p>输出：一个生成树<code>T</code>，连接所有节点并且权重最小。<span class="math inline">\(w(T)=\sum_{(u,v)\in T}w(u,v)\)</span>.</p><h2 id="optimal-substructure">3. Optimal substructure</h2><p>移去最小生成树中的任意一个边，然后T被分为了两个子树<span class="math inline">\(T_1\)</span>和<span class="math inline">\(T_2\)</span>.</p><p><strong>Theorem:</strong> 子树<span class="math inline">\(T_1\)</span>是子图<span class="math inline">\(G_1\)</span>的最小生成树，子树<span class="math inline">\(T_2\)</span>是子图<span class="math inline">\(G_2\)</span>的最小生成树。</p><p><strong>Proof：</strong> cut and paste方法：<span class="math inline">\(w(T)=w(u,v)+w(T_1)+w(T_2)\)</span>.</p><p>如果<span class="math inline">\(T_1&#39;\)</span>是比<span class="math inline">\(T_1\)</span>对于<span class="math inline">\(G_1\)</span>更小的生成树这样<span class="math inline">\(T&#39;=\{(u,v)\}\cup T&#39;\cup T_2\)</span>就是比<span class="math inline">\(T\)</span>更小的生成树。这是与假设冲突的。</p><h2 id="greedy-choice">4. Greedy choice</h2><p><strong>Greedy-choice property：</strong>一个局部最优解也是全局最优解。</p><p><strong>Theorem：</strong> <span class="math inline">\(T\)</span>是<span class="math inline">\(G\)</span>的最小生成树，<span class="math inline">\(A\)</span>是<span class="math inline">\(V\)</span>的子集，假设<span class="math inline">\((u,v)\in E\)</span>是<span class="math inline">\(A\)</span>到<span class="math inline">\(V-A\)</span>权重最小的边，那么<span class="math inline">\((u,v)\in T\)</span>.</p><p><strong>Proof:</strong> 假设<span class="math inline">\((u,v)\notin T\)</span>，cut and paste.考虑T中从u到v的唯一简单路径。(u,v)和这条路径的第一个A到V-A的边交换，这样T变得更小了，假设冲突。</p><h2 id="prims-greedy-mst-algorithm">5. Prim’s greedy MST algorithm</h2><p><strong>IDEA:</strong> V-A维护为一个优先队列Q，将A与V之间最小权值边的权值当作Q的key.</p><p><img src="https://i.bmp.ovh/imgs/2021/03/693459b05e1f41f7.png" style="zoom:67%;" /></p><p>不同数据结构时间复杂度对比：</p><p><img src="https://i.bmp.ovh/imgs/2021/03/79b2ab6be27e4594.png" style="zoom:67%;" /></p><p>如今最好算法：</p><ul><li>Karger, Klein, and Tarjan [1993].</li><li>Randomized algorithm.</li><li>O(V + E) expected time</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;MIT算法导论课程：Lec16 贪婪算法，最小生成树，对应书上的章节：16.1-16.3 and 22.1, Chapter 23&lt;/p&gt;</summary>
    
    
    
    <category term="算法导论MIT" scheme="http://example.com/categories/%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BAMIT/"/>
    
    
    <category term="学习笔记" scheme="http://example.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>Lec15 动态规划，最长公共子序列</title>
    <link href="http://example.com/2021/03/28/Lec15%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%EF%BC%8C%E6%9C%80%E9%95%BF%E5%85%AC%E5%85%B1%E5%AD%90%E5%BA%8F%E5%88%97/"/>
    <id>http://example.com/2021/03/28/Lec15%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%EF%BC%8C%E6%9C%80%E9%95%BF%E5%85%AC%E5%85%B1%E5%AD%90%E5%BA%8F%E5%88%97/</id>
    <published>2021-03-28T08:14:58.000Z</published>
    <updated>2021-03-29T00:35:15.630Z</updated>
    
    <content type="html"><![CDATA[<p>MIT算法导论课程：Lec15 动态规划，最长公共子序列，对应书上的章节：Chapter 15</p><span id="more"></span><h2 id="longest-common-subsequence">1.Longest common subsequence</h2><p><strong>最长公共子序列</strong>：给两个序列<code>x[1..m]</code>和<code>y[1..n]</code>，找到两者之间最长的公共子序列。</p><p>x: ABCBDAB；y:BDCABA。可以看出BCBA|BDAB|BCAB=LCS(x,y)。</p><p><strong>Brute-force LCS algorithm</strong></p><p>检查x中所有的子序列在y中是否存在。一个子序列检查需要<span class="math inline">\(O(n)\)</span>的时间，x中有<span class="math inline">\(2^m\)</span>的子序列，最坏运行时间为：<span class="math inline">\(O(n2^m)\)</span>.</p><p><strong>Towards a better algorithm</strong></p><p>考虑x,y的前缀。定义<span class="math inline">\(C[i,j]=|LCS(x[1..i]),y[1..j]|\)</span>。然后<span class="math inline">\(c[m,n]=|LCS(x,y)|\)</span>。</p><p>转换公式：<span class="math inline">\(c[i, j]=\left\{\begin{array}{ll} c[i-1, j-1]+1 &amp; \text { if } x[i]=y[j], \\ \max \{c[i-1, j], c[i, j-1]\} &amp; \text { otherwise. } \end{array}\right.\)</span></p><p>证明：略。</p><h2 id="optimal-substructure">2. Optimal substructure</h2><p>最优子结构：问题（实例）的最佳解决方案包含子问题的最佳解决方案。</p><p>例子：如果<span class="math inline">\(z=LCS(x,y)\)</span>，那么任何z的前缀是一个x前缀与y前罪的LCS。</p><p><strong>Recursive algorithm for LCS</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">LCS(x,y,i,j)</span><br><span class="line">if x[i]&#x3D;y[j] then</span><br><span class="line">c[i,j]&#x3D;LCSV(x,y,i-1,j-1)+1</span><br><span class="line">else</span><br><span class="line">c[i,j]&#x3D;max&#123;LCS(x,y,i-1,j),LCS(x,y,i,j-1)&#125;</span><br></pre></td></tr></table></figure><h2 id="overlapping-subproblems">3. Overlapping subproblems</h2><p>重叠子问题：递归解决方案包含多次重复的“少量”独特子问题。两个长度为m和n的字符串的不同LCS子问题的数量仅为<span class="math inline">\(mn\)</span></p><p>Memoization : 计算完一个子问题的解决方案后，将其存储在表中。后续调用检查表以避免重做工作。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">LCS(x,y,i,j)</span><br><span class="line">if c[i,j]&#x3D;NIL</span><br><span class="line">if x[i]&#x3D;y[j] then</span><br><span class="line">c[i,j]&#x3D;LCSV(x,y,i-1,j-1)+1</span><br><span class="line">else</span><br><span class="line">c[i,j]&#x3D;max&#123;LCS(x,y,i-1,j),LCS(x,y,i,j-1)&#125;</span><br></pre></td></tr></table></figure><p>IDEA：自下而上计算表格。</p><p><img src="https://i.bmp.ovh/imgs/2021/03/ad176424e959bae4.png" style="zoom:67%;" /></p><ul><li>Time=<span class="math inline">\(\Theta(mn)\)</span></li><li>Space=<span class="math inline">\(\Theta(mn)\)</span></li></ul><p>可以优化到<span class="math inline">\(O(min\{m,n\})\)</span></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;MIT算法导论课程：Lec15 动态规划，最长公共子序列，对应书上的章节：Chapter 15&lt;/p&gt;</summary>
    
    
    
    <category term="算法导论MIT" scheme="http://example.com/categories/%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BAMIT/"/>
    
    
    <category term="学习笔记" scheme="http://example.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>Lec17 最短路径算法：Dijkstra算法，广度优先搜索</title>
    <link href="http://example.com/2021/03/28/Lec17%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%E7%AE%97%E6%B3%95%EF%BC%9ADijkstra%E7%AE%97%E6%B3%95%EF%BC%8C%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2/"/>
    <id>http://example.com/2021/03/28/Lec17%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%E7%AE%97%E6%B3%95%EF%BC%9ADijkstra%E7%AE%97%E6%B3%95%EF%BC%8C%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2/</id>
    <published>2021-03-28T08:14:58.000Z</published>
    <updated>2021-03-29T00:36:28.570Z</updated>
    
    <content type="html"><![CDATA[<p>MIT算法导论课程：Lec17 最短路径算法：Dijkstra算法，广度优先搜索 ，对应书上的章节：Section 22.2</p><span id="more"></span><h2 id="properties-of-shortest-paths">1. Properties of shortest paths</h2><p><strong>Paths in graphs</strong></p><p>考虑一个带权重边的图，路径的权重为<span class="math inline">\(w(p)=\sum_{i=1}^{k-1}w(v_i,v{i+1})\)</span>.</p><p>从u到v的最短路径为：<span class="math inline">\(\delta(u,v)=min\{w(p:p\ is\ a\ path\ from\ u\ to \ v)\}\)</span>。</p><p>如果<code>u</code>到<code>v</code>不存在路径则<span class="math inline">\(\delta(u,v)=+\infty\)</span>.</p><p>如果边的权重可以为负数，那么最短路径可能不存在，因为可能有一个负数的环。</p><p><strong>Optimal substructure</strong></p><p>Theorem: 最短路径的子路径也是最短路径。</p><p>Proof: Cut and Paste.</p><p><strong>Triangle inequality</strong></p><p>Theorem: 对于所有的<span class="math inline">\(u,v,x,\in V\)</span>，有：<span class="math inline">\(\delta(u,v)\leq \delta(u,x)+\delta(x,v)\)</span>.</p><p><strong>Single-source shortest paths</strong></p><p>假设边的权重都是非负的，所有的最短路径都是存在的。</p><p>IDEA：贪心（Greedy）.</p><ol type="1"><li><p>维护一个从s到该集合S的点的最短路径已知的集合。</p></li><li><p>每一步从<span class="math inline">\(v\in V-S\)</span>中添加一个估计距离s最短点到S中。</p></li><li><p>更新到v的距离。</p></li></ol><h2 id="dijkstras-algorithm">2. Dijkstra’s algorithm</h2><p>算法：</p><p><img src="https://i.bmp.ovh/imgs/2021/03/24742d4fcf59b0a3.png" style="zoom:67%;" /></p><p>松弛操作部分可以理解为对三角不等式的约束进行不断松弛的操作，使之满足，再松弛过程中实现了降序排列Key的操作。</p><h2 id="correctness">3. Correctness</h2><p><strong>Part 1</strong></p><p>Lemma:初始化<span class="math inline">\(d[s]=0,其他的点d[v]=+\infty\)</span>，在整个过程中对于所有<span class="math inline">\(v\in V,d[v]\geq \delta(s,v)\)</span>。</p><p>proof: 反证法，假设<code>v</code>是第一个<span class="math inline">\(d[v]&lt;\delta(s,v)\)</span>的点，<code>u</code>是导致改变的点<span class="math inline">\(d[v]=d[u]+w(u,v)\)</span>。所以有一下矛盾。</p><p><img src="https://i.bmp.ovh/imgs/2021/03/d146f53ed90da685.png" style="zoom:67%;" /></p><p><strong>Part 2</strong></p><p>Lemma：<code>u</code>是<code>v</code>最短路径的前一节点，如果<span class="math inline">\(d[u]=\delta(s,u)\)</span>，并且边<span class="math inline">\((u,v)\)</span>是已经松弛了的，则我们有通过松弛后<span class="math inline">\(d[v]=\delta(s,v)\)</span>。</p><p>proof：松弛过程实现</p><p><strong>Part 3</strong></p><p>Lemma：Dijkstra 算法最后会计算出所有的<span class="math inline">\(d[v]=\delta(s,v)\)</span>.</p><p>Proof：v 添加到S中时可以保证<span class="math inline">\(d[v]=\delta(s,v)\)</span>，通过反证法证明。假设u时第一个添加到S中去<span class="math inline">\(d[u]&gt;\delta(s,u)\)</span>的。假设y是第一个u的最短路径中的S-V中的节点。当x添加时，<span class="math inline">\(d[x]=\delta(s,x)\)</span>，边(x,y)是松弛过的，<span class="math inline">\(d[y]=\delta(s,y)\leq\delta(s,u)&lt;d[u]\)</span>。但是<span class="math inline">\(d[u]\leq d[y]\)</span>，矛盾了。</p><p><img src="https://i.bmp.ovh/imgs/2021/03/7c4193cf01f161eb.png" /></p><h2 id="analysis">4. Analysis</h2><p><img src="https://i.bmp.ovh/imgs/2021/03/e6b587c28a6c44c2.png" style="zoom:67%;" /></p><p><img src="https://i.bmp.ovh/imgs/2021/03/83877cc356c79e83.png" style="zoom:67%;" /></p><h2 id="breadth-first-search">5. Breadth-first search</h2><p>假设对于所有的边<span class="math inline">\(w(u,v)=1\)</span> ，采用FIFO队列代替优先队列。</p><p><img src="https://i.bmp.ovh/imgs/2021/03/df1d68500b8b425f.png" /></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;MIT算法导论课程：Lec17 最短路径算法：Dijkstra算法，广度优先搜索 ，对应书上的章节：Section 22.2&lt;/p&gt;</summary>
    
    
    
    <category term="算法导论MIT" scheme="http://example.com/categories/%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BAMIT/"/>
    
    
    <category term="学习笔记" scheme="http://example.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>Lec04快速排序及随机化算法</title>
    <link href="http://example.com/2021/03/28/Lec04%E5%BF%AB%E6%8E%92%E5%8F%8A%E9%9A%8F%E6%9C%BA%E5%8C%96%E7%AE%97%E6%B3%95/"/>
    <id>http://example.com/2021/03/28/Lec04%E5%BF%AB%E6%8E%92%E5%8F%8A%E9%9A%8F%E6%9C%BA%E5%8C%96%E7%AE%97%E6%B3%95/</id>
    <published>2021-03-28T08:14:57.000Z</published>
    <updated>2021-03-29T00:25:42.039Z</updated>
    
    <content type="html"><![CDATA[<p>MIT算法导论课程：Lec04快速排序及随机化算法，对应书上的章节：Sections 5.1-5.3, Chapter 7</p><span id="more"></span><h2 id="quicksort">1. Quicksort</h2><ul><li><p>Proposed by C.A.R. Hoare in 1962.</p></li><li><p>Divide-and-conquer algorithm.</p></li><li><p>Sorts “in place” (like insertion sort, but not like merge sort).</p></li><li><p>Very practical (with tuning).</p></li></ul><h2 id="divide-and-conquer">2. Divide and conquer</h2><p>快排n个元素的数组</p><ol type="1"><li><p>Divide：选取pivot x，将数组中小于等于x的放在x的左边，大于等于的放在x的右边。</p></li><li><p>Conquer：递归的排两个子数组。</p></li><li><p>Combine：花销小。</p></li></ol><h2 id="partitioning">3. Partitioning</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">PARTITION(A,p,q)</span><br><span class="line">x&#x3D;A[p]</span><br><span class="line">i&#x3D;p</span><br><span class="line">for j in [p+1,q]</span><br><span class="line">do if A[j]&lt;&#x3D;x</span><br><span class="line">then i&#x3D;i+1</span><br><span class="line">exchange(A[i],A[j])</span><br><span class="line">exchange(A[p],A[i])</span><br><span class="line">return i</span><br></pre></td></tr></table></figure><p>Pseudocode for quicksort</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">QUICKSORT(A,p,r)</span><br><span class="line">if p&lt;r</span><br><span class="line">then q&#x3D;PARTITION(A,p,r)</span><br><span class="line">QUICKSORT(A,p,q-1)</span><br><span class="line">QUICKSORT(A,q+1,r)</span><br></pre></td></tr></table></figure><h2 id="worst-case-analysis">4. Worst-case analysis</h2><p>worse-case 已经排序或者逆序的情况下。划分的其中一边为0。</p><p><span class="math inline">\(T(n)=T(0)+T(n-1)+\Theta(n)=T(n-1)+\Theta(n)=\Theta(n^2)\)</span></p><h2 id="best-case-analysis">5. Best-case analysis</h2><p>如果幸运的话，平均划分(evenly)。</p><p><span class="math inline">\(T(n)=2T(n/2)+\Theta(n)=\Theta(n\lg n)\)</span></p><p>如果9 1划分：</p><p><span class="math inline">\(T(n)=T(\frac{1}{10}n)+T(\frac{9}{10}n)+\Theta(n)\)</span></p><h2 id="more-intuition">6. More intuition</h2><p>如果在lucky和unlucky交替进行。</p><p><span class="math inline">\(L(n)=2U(n/2)+\Theta(n)\)</span></p><p><span class="math inline">\(U(n)=L(n-1)+\Theta(n)\)</span></p><p><span class="math inline">\(L(n)=2(L(n/2-1)+\Theta(n/2))+\Theta(n)=\Theta(n\lg n)\)</span> （2式子替换到1式替换）</p><h2 id="randomized-quicksort">7. Randomized quicksort</h2><ol type="1"><li>Partition around a random element.</li><li>Running time is independent of the input order.</li><li>No specific input elicits the worst-case behavior.</li><li>The worst case is determined only by the output of a random-number generator.</li></ol><p><span class="math display">\[\begin{aligned}E[T(n)] &amp;=E\left[\sum_{k=0}^{n-1} X_{k}(T(k)+T(n-k-1)+\Theta(n))\right] \\&amp;=\sum_{k=0}^{n-1} E\left[X_{k}(T(k)+T(n-k-1)+\Theta(n))\right] \\&amp;=\sum_{k=0}^{n-1} E\left[X_{k}\right] \cdot E[T(k)+T(n-k-1)+\Theta(n)] 独立的可以分开\\&amp;=\frac{1}{n} \sum_{k=0}^{n-1} E[T(k)]+\frac{1}{n} \sum_{k=0}^{n-1} E[T(n-k-1)]+\frac{1}{n} \sum_{k=0}^{n-1} \Theta(n) \\ &amp;=\frac{2}{n} \sum_{k=1}^{n-1} E[T(k)]+\Theta(n) \quad \begin{array}{l}\end{array}\end{aligned}\]</span></p><p><strong>Prove:</strong> <span class="math inline">\(E[T(n)]&lt;=an\lg n\)</span> for constant a&gt;0</p><p><strong>Use fact</strong> <span class="math inline">\(\sum_{k=2}^{n-1} k \lg k \leq \frac{1}{2} n^{2} \lg n-\frac{1}{8} n^{2}\)</span></p><p><strong>Substitution method</strong> <span class="math display">\[\begin{aligned}E[T(n)] &amp; \leq \frac{2}{n} \sum_{k=2}^{n-1} a k \lg k+\Theta(n) \\&amp;=\frac{2 a}{n}\left(\frac{1}{2} n^{2} \lg n-\frac{1}{8} n^{2}\right)+\Theta(n) \\&amp;=a n \lg n-\left(\frac{a n}{4}-\Theta(n)\right) \\&amp; \leq a n \lg n\end{aligned}\]</span> 如果a选择足够大，<span class="math inline">\(an/4\)</span>大过<span class="math inline">\(\Theta(n)\)</span></p><h2 id="quicksort-in-practice">8. Quicksort in practice</h2><p>通常比合并排序快两倍</p><p>快排通过代码微调可以提升</p><p>Quicksort behaves well even with caching and virtual memory.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;MIT算法导论课程：Lec04快速排序及随机化算法，对应书上的章节：Sections 5.1-5.3, Chapter 7&lt;/p&gt;</summary>
    
    
    
    <category term="算法导论MIT" scheme="http://example.com/categories/%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BAMIT/"/>
    
    
    <category term="学习笔记" scheme="http://example.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>Lec03分治法</title>
    <link href="http://example.com/2021/03/28/Lec03%E5%88%86%E6%B2%BB%E6%B3%95/"/>
    <id>http://example.com/2021/03/28/Lec03%E5%88%86%E6%B2%BB%E6%B3%95/</id>
    <published>2021-03-28T08:14:57.000Z</published>
    <updated>2021-03-29T00:24:13.698Z</updated>
    
    <content type="html"><![CDATA[<p>MIT算法导论课程：Lec03分治法，对应书上的章节：Sections 4.2 and 30.1</p><span id="more"></span><h2 id="分治法">1. 分治法</h2><ol type="1"><li>Divide：将问题划分为多个子问题</li><li>Conquer：通过递归解决子问题</li><li>Combine：将子问题的解合并为大问题的解</li></ol><h2 id="merge-sort">2. Merge sort</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">algorithm：</span><br><span class="line">1. Divide：划分为2个数组</span><br><span class="line">2. Conquer：递归的排序两个数组</span><br><span class="line">3. Combine：将两个有序数组合并，需要线性时间</span><br></pre></td></tr></table></figure><p><span class="math inline">\(T(n)=2T(n/2)+\Theta(n)\)</span> 根据主方法，<span class="math inline">\(T(n)=\Theta(n\lg n)\)</span></p><h2 id="binary-search">3. Binary search</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">algorithm:</span><br><span class="line">1. Divide：找到中间元素</span><br><span class="line">2. Conquer：递归查找其中一个子数组</span><br><span class="line">3. Combine：合并</span><br></pre></td></tr></table></figure><p><span class="math inline">\(T(n)=T(n/2)+\Theta(1)\)</span> 根据主方法，<span class="math inline">\(T(n)=\Theta(\lg n)\)</span></p><h2 id="powering-a-number">4. Powering a number</h2><p>algorithm:</p><p><img src="https://i.bmp.ovh/imgs/2021/01/bdd497742fae9942.png" style="zoom:50%;" /></p><p><span class="math inline">\(T(n)=T(n/2)+\Theta(1)\)</span> 根据主方法，<span class="math inline">\(T(n)=\Theta(\lg n)\)</span></p><h2 id="fibonacci-numbers">5. Fibonacci numbers</h2><p><strong>朴素的递归算法（Naive recursive algorithm）</strong> <span class="math inline">\(T(n)=\Omega(\phi^n),\phi=(1+\sqrt 5)/2\)</span> golden ratio。</p><p><strong>自底向上（Bottom-up）：</strong>从下往上计算。<span class="math inline">\(T(n)=\Theta(n)\)</span></p><p><strong>朴素的递归平方（Naive recursive squaring）：</strong> 通过公式计算，<span class="math inline">\(F_n=\phi^n/\sqrt 5\)</span>最近的整数。但是这个方法不安全，浮点运算容易产生舍入误差。</p><p><strong>递归平方（Recursive squaring）：</strong> 通过如下的公式计算，通过乘法通过二分法优化 <span class="math inline">\(T(n)=\Theta(\lg n)\)</span>，可以通过归纳法证明。 <span class="math display">\[\left[\begin{array}{cc}F_{n+1} &amp; F_{n} \\F_{n} &amp; F_{n-1}\end{array}\right]=\left[\begin{array}{cc}1 &amp; 1 \\1 &amp; 0\end{array}\right]^{n}\]</span></p><h2 id="matrix-multiplication">6. Matrix multiplication</h2><p><strong>标准算法（Standard algorithm）</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">for i in [1,n]:</span><br><span class="line">do for j in [1,n]:</span><br><span class="line">do cij&#x3D;0</span><br><span class="line">for k in [1,n]:</span><br><span class="line">do cij&#x3D;cij+aik*akj</span><br></pre></td></tr></table></figure><p><span class="math inline">\(T(n)=\Theta(n^3)\)</span></p><p><strong>分治法（Divide-and-conquer algorithm）</strong></p><p>将nxn的矩阵分为4个<span class="math inline">\((n/2)*(n/2)\)</span>的子矩阵，如下图所示：</p><p><img src="https://i.bmp.ovh/imgs/2021/01/58564478786e721a.png" style="zoom: 50%;" /></p><p><span class="math inline">\(T(n)=8T(n/2)+\Theta(n^2)\)</span>，主方法得<span class="math inline">\(T(n)=\Theta(n^3)\)</span>，没有改进。</p><p><strong>Strassen’s algorithm：</strong>将上面提到的方法乘法次数从8降到7。 <span class="math display">\[\begin{array}{ll}P_{1}=a \cdot(f-h) &amp; r=P_{5}+P_{4}-P_{2}+P_{6} \\P_{2}=(a+b) \cdot h &amp; s=P_{1}+P_{2} \\P_{3}=(c+d) \cdot e &amp; t=P_{3}+P_{4} \\P_{4}=d \cdot(g-e) &amp; u=P_{5}+P_{1}-P_{3}-P_{7} \\P_{5}=(a+d) \cdot(e+h) \\P_{6}=(b-d) \cdot(g+h) \\P_{7}=(a-c) \cdot(e+f)\end{array}\]</span> 进行7次乘法，18次加法。<span class="math inline">\(T(n)=8T(n/2)+\Theta(n^2)\)</span>，由主方法计算得<span class="math inline">\(T(n)=\Theta(n^{lg 7})\)</span>。</p><h2 id="vlsi-tree-layout">7. VLSI tree layout</h2><p>problem：使用最小的面积将具有n个叶子的完整二叉树嵌入网格中。</p><p>以下介绍两种方法：</p><p>方法一：</p><p><img src="https://i.bmp.ovh/imgs/2021/01/985a319949fe5f07.png" style="zoom:50%;" /></p><p>方法二：</p><p><img src="https://ftp.bmp.ovh/imgs/2021/03/25b53265a95180f2.png" style="zoom:50%;" /></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;MIT算法导论课程：Lec03分治法，对应书上的章节：Sections 4.2 and 30.1&lt;/p&gt;</summary>
    
    
    
    <category term="算法导论MIT" scheme="http://example.com/categories/%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BAMIT/"/>
    
    
    <category term="学习笔记" scheme="http://example.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>Lec05线性时间排序</title>
    <link href="http://example.com/2021/03/28/Lec05%E7%BA%BF%E6%80%A7%E6%97%B6%E9%97%B4%E6%8E%92%E5%BA%8F/"/>
    <id>http://example.com/2021/03/28/Lec05%E7%BA%BF%E6%80%A7%E6%97%B6%E9%97%B4%E6%8E%92%E5%BA%8F/</id>
    <published>2021-03-28T08:14:57.000Z</published>
    <updated>2021-03-29T00:26:55.175Z</updated>
    
    <content type="html"><![CDATA[<p>MIT算法导论课程：Lec05线性时间排序，对应书上的章节：Sections 8.1-8.3</p><span id="more"></span><h2 id="sorting-lower-bounds">1.Sorting Lower Bounds</h2><p>insertion sort, merge sort, quicksort, heapsort 都只能对两个元素进行比较来确定顺序。</p><p><strong>prove</strong> ：比较排序算法的最小时间的是<span class="math inline">\(O(n\lg n)\)</span></p><p>通过Decision-tree来证明，Decision-tree入下所示。节点<code>1:2</code>表示数组中A[1]和A[2]进行比较，向左表示A[1]&lt;=A[2]，向右表示A[1]&gt;=A[2]。所有排序的比较过程都可以用树中的一条路径表示。</p><p><img src="https://i.bmp.ovh/imgs/2021/02/d15b4f2287ee343c.png" style="zoom:50%;" /></p><p><strong>Theorem:</strong> Any decision tree that can sort n elements must have height Ω(n lg n).</p><p><strong>proof：</strong> 树中的叶子树<span class="math inline">\(&gt;=n!\)</span>因为有<span class="math inline">\(n!\)</span>个可能的排列组合数。<span class="math inline">\(n!\leq 2^g,h\geq\Omega(n\lg n)\)</span> <span class="math display">\[\begin{aligned}h &amp; \geq \lg (n !)  \\&amp; \geq \lg \left((n / e)^{n}\right) (Stirling’s formula)\\&amp;=n \lg n-n \lg e \\&amp;=\Omega(n \lg n)\end{aligned}\]</span></p><p>Heapsort and merge sort are asymptotically optimal comparison sorting algorithms.</p><h2 id="sorting-in-linear-time">2. Sorting in linear time</h2><h3 id="counting-sort">2.1 Counting sort</h3><p>对数组中的树进行了假设。</p><p><strong>Input:</strong> <span class="math inline">\(A[1,...,n],A[i]\in \{1,2,...,k\}\)</span></p><p><strong>Output:</strong><span class="math inline">\(B[1,...,n]\)</span></p><p><strong>Auxiliary storage:</strong> <span class="math inline">\(C[1..k]\)</span></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">for i ← 1 to k</span><br><span class="line">do C[i] ← 0</span><br><span class="line">for j ← 1 to n</span><br><span class="line">do C[A[ j]] ← C[A[ j]] + 1 ⊳ C[i] &#x3D; |&#123;key &#x3D; i&#125;|</span><br><span class="line">for i ← 2 to k</span><br><span class="line">do C[i] ← C[i] + C[i–1] ⊳ C[i] &#x3D; |&#123;key ≤ i&#125;|</span><br><span class="line">for j ← n downto 1</span><br><span class="line">do B[C[A[j]]] ← A[j]</span><br><span class="line">C[A[j]] ← C[A[j]] – 1</span><br></pre></td></tr></table></figure><p><strong>时间复杂度：</strong> <span class="math inline">\(\Theta(n+k)\)</span></p><p><strong>Stable sorting：</strong>it preserves the input order among equal elements.</p><h2 id="radix-sort基数排序">2.2 Radix sort基数排序</h2><p>digit-by-digit sort，sort on least-significant digit first with auxiliary stable sort.</p><p><strong>Correctness of radix sort</strong></p><p>假设低<code>t-1</code>位都已经排序，对第<code>t</code>位排序，在<code>t</code>位不同的数按照顺序排序，相同的数的顺序和输入一样就可以保证正确的排序。</p><p><strong>Analysis of radix sort</strong></p><p>排序n个单词，每个单词有b个bits，以<span class="math inline">\(2^r\)</span>为一位有<span class="math inline">\(b/r\)</span>位。Counting sort的复杂度<span class="math inline">\(\Theta(n+k)\)</span>，所以时间复杂度为<span class="math inline">\(T(n,b)=\Theta(\frac{b}{r}(n+2^r))\)</span>，选择合适的r来最小化<span class="math inline">\(T(n,b)\)</span>，通过求导的方法，<span class="math inline">\(r=\lg n\)</span>从而<span class="math inline">\(T(n,b)=\Theta(bn/\lg n)\)</span>，对于数组大小在<span class="math inline">\([0,n^d-1]\)</span>之间，<span class="math inline">\(b=d\lg n\)</span> ，radix sort的复杂度为<span class="math inline">\(\Theta(dn)\)</span>。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;MIT算法导论课程：Lec05线性时间排序，对应书上的章节：Sections 8.1-8.3&lt;/p&gt;</summary>
    
    
    
    <category term="算法导论MIT" scheme="http://example.com/categories/%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BAMIT/"/>
    
    
    <category term="学习笔记" scheme="http://example.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>Lec07哈希表</title>
    <link href="http://example.com/2021/03/28/Lec07%E5%93%88%E5%B8%8C%E8%A1%A8/"/>
    <id>http://example.com/2021/03/28/Lec07%E5%93%88%E5%B8%8C%E8%A1%A8/</id>
    <published>2021-03-28T08:14:57.000Z</published>
    <updated>2021-03-29T00:28:42.998Z</updated>
    
    <content type="html"><![CDATA[<p>MIT算法导论课程：Lec07哈希表，对应书上的章节：Sections 11.1-11.3</p><span id="more"></span><h2 id="symbol-table-problem">1. Symbol-table problem</h2><p><img src="https://i.bmp.ovh/imgs/2021/03/f477d74188917789.png" style="zoom:67%;" /></p><h2 id="direct-access-tables">1. Direct-access tables</h2><p>IDEA:假设keys来自集合<span class="math inline">\(U\in\{0,1,...,m-1\}\)</span>，并且keys都是distinct的。创建一个数组<span class="math inline">\(T[0,...,m-1]\)</span>。</p><p><img src="https://i.bmp.ovh/imgs/2021/03/f0493f6664f6a4fe.png" style="zoom:50%;" /></p><p>operations的worst-time为<span class="math inline">\(\Theta(1)\)</span></p><p><strong>hash and collision</strong></p><p>Hashing:Hash function h maps keys &quot;randomly&quot; into slots of table T.</p><p>When a record to be inserted maps to an already occupied slot in T, a collision occurs.</p><p>## 2. Resolving collisions by chaining</p><p><strong>IDEA:</strong>Link records in the same slot into a list</p><p><strong>worst case:</strong>Every key hashes to the same slot. Access time:<span class="math inline">\(\Theta(n)\)</span></p><p><strong>Average-case:</strong> We make the assumption of simple uniform hashing. <code>n</code> be the number of keys in the table, and let <code>m</code> be the number of slots.<span class="math inline">\(\alpha=n/m\)</span> average number of keys per slot.</p><ul><li><p>unsuccessful search:<span class="math inline">\(\Theta(1+\alpha)\)</span>. (apply hash function and access slot+search the list)</p></li><li><p>A successful search has same asymptotic bound. 证明难，见书本.</p></li></ul><h2 id="choosing-hash-functions">3. Choosing hash functions</h2><p>均匀分布很难保证，好的hash函数应该满足以下条件</p><ul><li>尽量均匀分布</li><li>keys的规律性不影响均匀性</li></ul><p><strong>Division method</strong></p><p>Assume all keys are integers, and define <span class="math inline">\(h(k)=k\ mod\ m\)</span>.</p><p>缺点：不要选取有小divisor d的m，回影响分布均匀。if <span class="math inline">\(m=2^r\)</span>，then the hash doesn’t even depend on all the bits of k.</p><p>Pick m to be a prime not too close to a power of 2 or 10.但是table size设置为质数不方便。</p><p>除法在计算机比较慢。</p><p><strong>Multiplication method</strong></p><p>Assume that all keys are integers, <span class="math inline">\(m = 2^r\)</span>, and our computer has <code>w-bit</code> words. Define <span class="math inline">\(h(k)=(A*k\ mod2^w)rsh(w-r)\)</span>,where <code>rsh</code> is the “bitwise right-shift” operator and A is an odd integer in the range <span class="math inline">\(2^{w–1} &lt; A &lt; 2^w\)</span>.</p><ul><li>Don’t pick A too close to <span class="math inline">\(2^{w–1}\)</span> or <span class="math inline">\(2^w\)</span>.</li><li>比除法快</li><li>rsh也快</li></ul><p><img src="https://i.bmp.ovh/imgs/2021/03/c284d9544692182d.png" /></p><h2 id="resolving-collisions-by-open-addressing-开放寻址">4. Resolving collisions by open addressing 开放寻址</h2><ul><li>no storage for link.</li><li>Insertion systematically probes the table until an empty slot is found.</li><li>The hash function depends on both the <strong>key</strong> and <strong>probe number</strong></li><li>The probe sequence 〈h(k,0), h(k,1), …, h(k,m–1)〉 should be a permutation of {0, 1, …, m–1}.</li><li>The table may fill up, and deletion is difficult (but not impossible). 因为删除一个key后可能会影响其他key的搜索。</li></ul><p>Search uses the same probe sequence, terminating successfully if it finds the key and unsuccessfully if it encounters an empty slot.搜索使用相同的探针序列，如果找到密钥，则成功终止，如果遇到空插槽则不成功。</p><h3 id="probing-strategiesprobing-strategies">4.1 Probing strategiesProbing strategies</h3><p><strong>1. Linear probing：</strong> <span class="math inline">\(h(k,i) = (h′(k) + i) mod m\)</span>，这种方法虽然简单，但受到主聚类（primary clustering）的影响，其中长期占用的插槽会积聚起来，从而增加平均搜索时间。此外，长期占用的插槽往往变长。通常结合<strong>Multiplication method</strong>使用。</p><p><strong>2. Double hashing：</strong> <span class="math inline">\(h(k,i) = (h_1(k) + i⋅ h_2(k))\ mod\ m\)</span></p><p>This method generally produces excellent results, but <span class="math inline">\(h_2(k)\)</span> must be relatively prime to m. One way is to make m a power of 2 and design <span class="math inline">\(h_2(k)\)</span> to produce only odd numbers.</p><h3 id="analysis-of-open-addressing">4.2 Analysis of open addressing</h3><p>We make the assumption of uniform hashing: Each key is equally likely to have any one of the m! permutations as its probe sequence.</p><p><strong>Theorem.</strong> Given an open-addressed hash table with load factor$ α = n/m &lt; 1$, the expected number of probes in an unsuccessful search is at most <span class="math inline">\(1/(1–α)\)</span>.</p><p><strong>Proof</strong></p><ul><li>At least one probe is always necessary</li><li>With probability n/m, the first probe hits an occupied slot, and a second probe is necessary</li><li>With probability (n–1)/(m–1), the second probe hits an occupied slot, and a third probe is necessary.</li><li>With probability (n–2)/(m–2), the third probe hits an occupied slot, etc</li></ul><p>可以看出：<span class="math inline">\(\frac{n-i}{m-i}&lt;\frac{n}{m}=\alpha \text { for } i=1,2, \ldots, n\)</span></p><p><img src="https://cdn.mathpix.com/snip/images/EsuHCuh28rYDn2otEfxj2Bi5H-N7phYvrU1gf9aJNUY.original.fullsize.png" style="zoom:50%;" /></p><ul><li>If α is constant, then accessing an openaddressed hash table takes constant time.</li><li>If the table is half full, then the expected number of probes is 1/(1–0.5) = 2</li><li>If the table is 90% full, then the expected number of probes is 1/(1–0.9) = 10.</li><li>随着越来越满，速度越来越慢。</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;MIT算法导论课程：Lec07哈希表，对应书上的章节：Sections 11.1-11.3&lt;/p&gt;</summary>
    
    
    
    <category term="算法导论MIT" scheme="http://example.com/categories/%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BAMIT/"/>
    
    
    <category term="学习笔记" scheme="http://example.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>Lec06 顺序统计、中值</title>
    <link href="http://example.com/2021/03/28/Lec06%E9%A1%BA%E5%BA%8F%E7%BB%9F%E8%AE%A1_%E4%B8%AD%E5%80%BC/"/>
    <id>http://example.com/2021/03/28/Lec06%E9%A1%BA%E5%BA%8F%E7%BB%9F%E8%AE%A1_%E4%B8%AD%E5%80%BC/</id>
    <published>2021-03-28T08:14:57.000Z</published>
    <updated>2021-03-29T00:54:56.793Z</updated>
    
    <content type="html"><![CDATA[<p>MIT算法导论课程：Lec06 顺序统计、中值，对应书上的章节：Chapter 9</p><span id="more"></span><h2 id="order-statistics">1. Order statistics</h2><p>选出<code>n</code>个元素中第<code>i</code>小的数，<code>i=1:minimum</code>，<code>i = n: maximum</code>，<code>i = ⎣(n+1)/2⎦ or ⎡(n+1)/2⎤: median</code></p><p>很容易想到的一个方法是先排序在索引第<code>i</code>个元素。复杂度：<span class="math inline">\(\Theta(n\lg n)\)</span></p><h2 id="randomized-divide-and-conquer-algorithm">2. Randomized divide-and conquer algorithm</h2><p><strong>伪代码</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">RAND-SELECT(A,p,q,i) &#x2F;&#x2F;ith smallest of A[p...q]</span><br><span class="line">if p&#x3D;q then return A[p]</span><br><span class="line">r&#x3D;RAND-PARTITION(A,p,q)</span><br><span class="line">k&#x3D;r-p+1 &#x2F;&#x2F;k&#x3D;rank(A[r])</span><br><span class="line">if i&#x3D;k then return A[r]</span><br><span class="line">if i&lt;k</span><br><span class="line">then return RAND-SELECT(A,p,r-1,i)</span><br><span class="line">else return RAND-SELECT(A,r+1,q,i-k)</span><br></pre></td></tr></table></figure><p><strong>Analysis of expected time</strong></p><p>划分指示器</p><p><span class="math display">\[X_{k}=\left\{\begin{array}{ll}1 &amp; \text { if PARTITION generates a } k: n-k-1 \text { split, } \\0 &amp; \text { otherwise. }\end{array}\right.\]</span></p><p><span class="math display">\[\begin{aligned}T(n)=&amp;\left\{\begin{array}{cl}T(\max \{0, n-1\})+\Theta(n) &amp; \text { if } 0: n-1 \text { split, } \\T(\max \{1, n-2\})+\Theta(n) &amp; \text { if } 1: n-2 \text { split, } \\\vdots \\T(\max \{n-1,0\})+\Theta(n) &amp; \text { if } n-1: 0 \text { split }\end{array}\right.\\&amp;=\sum_{k=0}^{n-1} X_{k}(T(\max \{k, n-k-1\})+\Theta(n))\end{aligned}\]</span></p><p><img src="https://i.bmp.ovh/imgs/2021/02/bf9407c00e877ed9.png" style="zoom:67%;" /></p><p>再用替换法证明，<span class="math inline">\(E[T(n)]\leq cn\)</span>for constant c&gt;0。 <span class="math display">\[\begin{aligned}E[T(n)] &amp; \leq \frac{2}{n} \sum_{k=\lfloor n / 2\rfloor}^{n-1} c k+\Theta(n) \\&amp; \leq \frac{2 c\left(\frac{3}{8} n^{2}\right)+\Theta(n)}{n} \\&amp;=c n-\left(\frac{c n}{4}-\Theta(n)\right) \\&amp; \leq c n\end{aligned}\]</span> if c is chosen large enough so that cn/4 dominates the Θ(n)</p><p><strong>Summary of randomized order-statistic selection</strong></p><ul><li>线性期望时间</li><li>worst case：<span class="math inline">\(\Theta(n^2)\)</span></li></ul><h2 id="worst-case-linear-time-order-statistics">3. Worst-case linear-time order statistics</h2><p>[Blum, Floyd, Pratt, Rivest, Tarjan]</p><p>IDEA: Generate a good pivot recursively.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">SELECT(i, n)</span><br><span class="line">1. Divide the n elements into groups of 5. Find the median of each 5-element group by rote.</span><br><span class="line">2. Recursively SELECT the median x of the ⎣n&#x2F;5⎦ group medians to be the pivot.</span><br><span class="line">3. Partition around the pivot x. Let k &#x3D; rank(x).</span><br><span class="line">4. if i &#x3D; k then return x</span><br><span class="line">elseif i &lt; k</span><br><span class="line">then recursively SELECT the ith smallest element in the lower part</span><br><span class="line">else recursively SELECT the (i–k)th smallest element in the upper part</span><br><span class="line"></span><br><span class="line">3 4步和RAND-SELECT一样</span><br></pre></td></tr></table></figure><p><strong>Analysis</strong></p><p><img src="https://i.bmp.ovh/imgs/2021/02/543683de9884cb03.png" style="zoom:67%;" /></p><p><img src="https://i.bmp.ovh/imgs/2021/02/85706540dcd02af4.png" style="zoom:67%;" /></p><ul><li>实际上，此算法运行缓慢，因为n前面的常数很大</li><li>随机算法更加实用。</li></ul><p>练习：为什么不分成3组？</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;MIT算法导论课程：Lec06 顺序统计、中值，对应书上的章节：Chapter 9&lt;/p&gt;</summary>
    
    
    
    <category term="算法导论MIT" scheme="http://example.com/categories/%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BAMIT/"/>
    
    
    <category term="学习笔记" scheme="http://example.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>Lec10 平衡搜索树</title>
    <link href="http://example.com/2021/03/28/Lec10%E5%B9%B3%E8%A1%A1%E6%90%9C%E7%B4%A2%E6%A0%91/"/>
    <id>http://example.com/2021/03/28/Lec10%E5%B9%B3%E8%A1%A1%E6%90%9C%E7%B4%A2%E6%A0%91/</id>
    <published>2021-03-28T08:14:57.000Z</published>
    <updated>2021-03-29T00:31:00.881Z</updated>
    
    <content type="html"><![CDATA[<p>MIT算法导论课程：Lec10 平衡搜索树，对应书上的章节：Chapter 13</p><span id="more"></span><h2 id="balanced-search-trees">1. Balanced search trees</h2><p><strong>Balanced search tree:</strong> A search-tree data structure for which a height of <span class="math inline">\(O(\lg n)\)</span> is guaranteed when implementing a dynamic set of <code>n</code> items.</p><p>Examples:</p><ul><li><p>AVL trees</p></li><li>2-3 trees</li><li>2-3-4 trees</li><li>B-trees</li><li><p>Red-black trees</p></li></ul><h2 id="red-black-trees">2. Red-black trees</h2><p>This data structure requires an extra one bit <code>color</code> field in each node.</p><p><strong>Red-black properties:</strong></p><ul><li>Every node is either red or black.</li><li>The root and leaves (NIL’s) are black.</li><li>If a node is red, then its parent is black.</li><li>All simple paths from any node x to a descendant leaf have the same number of black nodes = black-height(x ).</li></ul><h2 id="height-of-a-red-black-tree">3. Height of a red-black tree</h2><p><strong>Theorem.</strong> A red-black tree with n keys has height <span class="math inline">\(h\leq 2\lg(n+1)\)</span>.</p><p><strong>Proof：</strong>（书上采用的是induction的方法证明）</p><p>INTUITION :</p><ol type="1"><li>Merge red nodes into their black parents.</li><li>This process produces a tree in which each node has 2, 3, or 4 children.</li><li>The 2-3-4 tree has uniform depth h′ of leaves.</li><li>We have h′ ≥ h/2, since at most half the leaves on any path are red.</li><li>The number of leaves in each tree is</li></ol><p><span class="math display">\[\begin{aligned}n+1 &amp; \geq2^{h&#39;}\\\lg (n+1) &amp;\geq h&#39;\geq h/2\\h&amp;\leq 2\lg(n+1)\end{aligned}\]</span></p><p><strong>Query operations</strong></p><p>The queries SEARCH, MIN, MAX, SUCCESSOR, and PREDECESSOR all run in <span class="math inline">\(O(\lg n)\)</span> time on a red-black tree with n nodes.</p><p><strong>Modifying operations</strong></p><p>The operations INSERT and DELETE cause modifications to the red-black tree:</p><ul><li>the operation itself,</li><li>color changes,</li><li>restructuring the links of the tree via “rotations”.</li></ul><h2 id="rotations">4. Rotations</h2><p><img src="https://i.bmp.ovh/imgs/2021/03/c1d1c45335eecca3.png" style="zoom:50%;" /></p><h2 id="insertion">5. Insertion</h2><p><strong>IDEA:</strong> Insert x in tree. Color x red. Only red-black property <code>3</code> might be violated. Move the violation up the tree by recoloring until it can be fixed with rotations and recoloring.</p><p><strong>Pseudocode:</strong></p><p><img src="https://i.bmp.ovh/imgs/2021/03/cd34bdf8902df62b.png" style="zoom:67%;" /></p><p><strong>三种情况</strong></p><p><img src="https://i.bmp.ovh/imgs/2021/03/44a459bb34ba3254.png" style="zoom:50%;" /></p><p><img src="https://i.bmp.ovh/imgs/2021/03/23b5148046e6a6c4.png" style="zoom:50%;" /></p><p><img src="https://i.bmp.ovh/imgs/2021/03/38afb328867bccb9.png" style="zoom:50%;" /></p><p><strong>Analysis</strong></p><ul><li>Case 1只对节点重新着色</li><li>如果Case 2,3出现进行1或2次旋转，然后结束</li></ul><p>Running time：<span class="math inline">\(O(\lg n)\)</span> with <span class="math inline">\(O(1)\)</span> rotations.</p><p>RB-DELETE：和插入具有渐进相同的运行时间和旋转次数。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;MIT算法导论课程：Lec10 平衡搜索树，对应书上的章节：Chapter 13&lt;/p&gt;</summary>
    
    
    
    <category term="算法导论MIT" scheme="http://example.com/categories/%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BAMIT/"/>
    
    
    <category term="学习笔记" scheme="http://example.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>Lec08 全域哈希和完全哈希</title>
    <link href="http://example.com/2021/03/28/Lec08%E5%85%A8%E5%9F%9F%E5%93%88%E5%B8%8C%E5%92%8C%E5%AE%8C%E5%85%A8%E5%93%88%E5%B8%8C/"/>
    <id>http://example.com/2021/03/28/Lec08%E5%85%A8%E5%9F%9F%E5%93%88%E5%B8%8C%E5%92%8C%E5%AE%8C%E5%85%A8%E5%93%88%E5%B8%8C/</id>
    <published>2021-03-28T08:14:57.000Z</published>
    <updated>2021-03-29T00:45:36.792Z</updated>
    
    <content type="html"><![CDATA[<p>MIT算法导论课程：Lec08 全域哈希和完全哈希，对应书上的章节：Section 11.5</p><span id="more"></span><h2 id="a-weakness-of-hashing">1. A weakness of hashing</h2><p>Problem: For any hash function h, a set of keys exists that can cause the average access time of a hash table to skyrocket.存在一组keys插入同一个slot，影响速度。</p><p>IDEA：random</p><h2 id="universal-hashing-全域哈希">2. Universal hashing 全域哈希</h2><p><strong>定义：</strong> Let <span class="math inline">\(U\)</span> be a universe of keys, and let <span class="math inline">\(H\)</span> be a finite collection of hash functions, each mapping <span class="math inline">\(U\)</span> to <span class="math inline">\(\{0, 1, …, m–1\}\)</span>. We say H is universal if for all <span class="math inline">\(x, y ∈ U\)</span>, where <span class="math inline">\(x ≠ y\)</span>, we have <span class="math inline">\(|{h\in H:h(x)=h(y)}|=|H|/m\)</span> .</p><p>随机的从H中选取h，x和y发生collision的概率是1/m.</p><h2 id="universality-theorem">3. Universality theorem</h2><p><strong>Theorem:</strong> Let h be a hash function chosen (uniformly) at random from a universal set H of hash functions. Suppose h is used to hash <code>n</code> arbitrary keys into the <code>m</code> slots of a table T. Then, for a given key x, we have<span class="math inline">\(E[collisions\  with x]&lt;n/m\)</span>. 其中 <span class="math inline">\(n/m\)</span>：load factor.</p><p>为什么是小于？</p><p><strong>Proof</strong></p><p>Let <span class="math inline">\(C_x\)</span> be the random variable denoting the <strong>total number</strong> of collisions of keys in T with x and let <span class="math inline">\(c_{x y}=\left\{\begin{array}{ll} 1 &amp; \text { if } h(x)=h(y) \\ 0 &amp; \text { otherwise. } \end{array}\right.\)</span> ，<span class="math inline">\(C_x\)</span>表示和<span class="math inline">\(x\)</span>碰撞的key的总数。</p><p>可知：<span class="math inline">\(E[c_xy]=1/m\)</span>，<span class="math inline">\(C_{x}=\sum_{y \in T-\{x\}} c_{x y}\)</span></p><p>可证： <span class="math display">\[\begin{aligned}E\left[C_{x}\right] &amp;=E\left[\sum_{y \in T-\{x\}} c_{x y}\right] \\&amp;=\sum_{y \in T-\{x\}} E\left[c_{x y}\right] \\&amp;=\sum_{y \in T-\{x\}} 1 / m \\&amp;=\frac{n-1}{m} . \end{aligned}\]</span></p><h2 id="constructing-a-set-of-universal-hash-functions">4. Constructing a set of universal hash functions</h2><p>Let <code>m</code> be prime.Decompose key <code>k</code> into <code>r + 1</code> digits, each with value in the set <code>&#123;0, 1, …, m–1&#125;</code>. That is, let <span class="math inline">\(k = 〈 k_0, k_1, …, k_r 〉\)</span>, where <span class="math inline">\(0 ≤ ki &lt; m\)</span>.将k进行“m进制表示”。</p><p><strong>Randomized strategy</strong></p><p>Pick <span class="math inline">\(a = 〈 a_0, a_1, …, a_r 〉\)</span> where each <span class="math inline">\(a_i\)</span> is chosen <strong>randomly</strong> from {0, 1, …, m–1}.</p><p>Define <span class="math inline">\(h_{a}(k)=\sum_{i=0}^{r} a_{i} k_{i} \bmod m\)</span> 对k和a做点积再对m取余。</p><p>How big is <span class="math inline">\(H=\{h_a\}\)</span>, <span class="math inline">\(|H|=m^{r+1}\)</span></p><p><strong>Theorem.</strong> The set <span class="math inline">\(H = {h_a}\)</span> is universal.</p><p><strong>Proof.</strong> Suppose that <span class="math inline">\(x = 〈x_0, x_1, …, x_r 〉\)</span> and$ y = 〈y_0, y_1, …, y_r 〉$ be distinct keys. Thus, they differ in at least one digit position, wlog position 0.（假设为0位置）For how many <span class="math inline">\(h_a ∈ H\)</span> do x and y collide. We must have<span class="math inline">\(h_a(x)=h_a(y)\)</span>. which implies that:<span class="math inline">\(\sum_{i=0}^{r} a_{i} x_{i} \equiv \sum_{i=0}^{r} a_{i} y_{i} \quad(\bmod m)\)</span>, <span class="math display">\[\sum_{i=0}^{r} a_{i}\left(x_{i}-y_{i}\right) \equiv 0 \quad(\bmod m)\]</span></p><p><span class="math display">\[a_{0}\left(x_{0}-y_{0}\right)+\sum_{i=1}^{r} a_{i}\left(x_{i}-y_{i}\right) \equiv 0 \quad(\bmod m)\]</span></p><p><span class="math display">\[a_{0}\left(x_{0}-y_{0}\right) \equiv-\sum_{i=1}^{r} a_{i}\left(x_{i}-y_{i}\right) \quad(\bmod m)\]</span></p><p>因为假设了<span class="math inline">\(x_0\neq y_0\)</span>，所以存在<span class="math inline">\((x_0-y_0)^{-1}\)</span>，所以： <span class="math display">\[a_{0} \equiv\left(-\sum_{i=1}^{r} a_{i}\left(x_{i}-y_{i}\right)\right) \cdot\left(x_{0}-y_{0}\right)^{-1} \quad(\bmod m)\]</span> 可以看出<span class="math inline">\(a_0\)</span>是由其他<span class="math inline">\(a_i\)</span>决定的，其他<span class="math inline">\(a_i\)</span>确定使得collide的<span class="math inline">\(a_0\)</span>就确定了。</p><p>如果发生碰撞，the number of h为<span class="math inline">\(m^r*1=|H|/m\)</span>.证明为全域哈希。</p><p><strong>Fact from number theory</strong></p><p><strong>Theorem.</strong> Let m be prime. For any <span class="math inline">\(z ∈ Z_m\)</span> such that <span class="math inline">\(z ≠ 0\)</span>, there exists a unique <span class="math inline">\(z^{–1} ∈ Z_m\)</span> such that:<span class="math inline">\(z \cdot z^{-1} \equiv 1 \quad(\bmod m)\)</span></p><p><img src="https://i.bmp.ovh/imgs/2021/03/c0d884026a0bece0.png" style="zoom:67%;" /></p><p>如果不是质数就不成立。</p><h2 id="perfect-hashing">5. Perfect hashing</h2><p>Given a set of n keys, construct a static hash table of size <span class="math inline">\(m = O(n)\)</span> such that <code>SEARCH</code> takes <span class="math inline">\(\Theta(1)\)</span> time in the worst case.固定keys静态表<span class="math inline">\(O(1)\)</span>时间查找。</p><p><strong>IDEA:</strong> Two level scheme with universal hashing at both levels.No collisions at level 2.</p><p><img src="https://i.bmp.ovh/imgs/2021/03/5a9f5a1ed1076a16.png" style="zoom:67%;" /></p><p>如果有<span class="math inline">\(n_i\)</span>个项被同时哈希到一级表的槽i，那么我们将有<span class="math inline">\(m_i=n_i^2\)</span>个槽在二级表。</p><p><strong>Theorem.</strong> Let H be a class of universal hash functions for a table of size <span class="math inline">\(m = n^2\)</span>. Then, if we use a random <span class="math inline">\(h ∈ H\)</span> to hash n keys into the table, the expected number of collisions is at most 1/2. 如果使用全域哈希<span class="math inline">\(m = n^2\)</span>，如果随机采样<span class="math inline">\(h ∈ H\)</span> 期望碰撞数为1/2.</p><p><strong>Proof</strong></p><p><img src="https://i.bmp.ovh/imgs/2021/03/205afe16921034e7.png" style="zoom:67%;" /></p><p><strong>马尔可夫不等式（Markov’s inequality）</strong></p><p>for any nonnegative random variable X, we have <span class="math inline">\(Pr\{X&gt;=t\}&lt;=E[X]/t\)</span></p><p><img src="https://i.bmp.ovh/imgs/2021/03/6905c87427f2ea37.png" style="zoom:50%;" /></p><p><strong>Corollary</strong>. The probability of no collisions is at least 1/2.</p><p>应用马尔可夫不等式，设置t=1， the probability of 1 or more collisions is at most 1/2。</p><p>Thus, just by testing random hash functions in H, we’ll quickly find one that works.</p><p>目标是创建静态表，所以这样证明很容易找到合适的哈希函数。</p><p><strong>Analysis of storage</strong></p><p>For the level-1 hash table T, choose m = n, and let ni be random variable for the number of keys that hash to slot i in T.By using <span class="math inline">\(n_i^2\)</span> slots for the level-2 hash table Si, the expected total storage required for the two-level scheme is therefore <span class="math display">\[E\left[\sum_{i=0}^{m-1} \Theta\left(n_{i}^{2}\right)\right]=\Theta(n)\]</span> since the analysis is identical to the analysis from recitation of the expected running time of <strong>bucket sort</strong>.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;MIT算法导论课程：Lec08 全域哈希和完全哈希，对应书上的章节：Section 11.5&lt;/p&gt;</summary>
    
    
    
    <category term="算法导论MIT" scheme="http://example.com/categories/%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BAMIT/"/>
    
    
    <category term="学习笔记" scheme="http://example.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>Lec09 二叉搜索树</title>
    <link href="http://example.com/2021/03/28/Lec09%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/"/>
    <id>http://example.com/2021/03/28/Lec09%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/</id>
    <published>2021-03-28T08:14:57.000Z</published>
    <updated>2021-03-29T00:51:33.597Z</updated>
    
    <content type="html"><![CDATA[<p>MIT算法导论课程：Lec09 二叉搜索树，对应书上的章节：Section 12.4</p><span id="more"></span><h2 id="binary-search-tree-sort">1. Binary-search-tree sort</h2><p>二叉搜索树排序过程如下：</p><p><img src="https://i.bmp.ovh/imgs/2021/03/87a24aa456fcd0b8.png" style="zoom:50%;" /></p><p>遍历树的时间为<span class="math inline">\(O(n)\)</span>，但是构建BST的时间是多少？</p><p>BST sort和quick sort很像：BST sort performs the same comparisons as quicksort, but in a different order!</p><h2 id="expected-node-depth">2. Expected node depth</h2><p>Assuming all input permutations are equally likely, we have：（BST sort performs the same comparisons as quicksort） <span class="math display">\[Average\ node\ depth=\frac{1}{n}E[\sum(comparisons\ to\ insert\ node\ i)]=\frac{1}{n}O(n\lg n)=O(\lg n)\]</span> 但是平均节点深度并不等于树的期望高度。</p><h2 id="analyzing-height">3. Analyzing height</h2><p><strong>Jensen’s inequality：</strong> <span class="math inline">\(f(E[X])\leq E[f(x)]\)</span> for any convex function f and random variable X.</p><p><strong>Exponential height：</strong> random variable <span class="math inline">\(Y_n=x^{X_n}\)</span>，where <span class="math inline">\(X_n\)</span> is the random varible denoting the height of BST.</p><p><strong>证明：</strong> Prove that <span class="math inline">\(2^{E[X_n]}\leq E[2^{X_n}]=E[Y_n]=O(n^3)\)</span>,hence that <span class="math inline">\(E[X_n]=O(\lg n)\)</span></p><p><strong>凸函数(Convex functions)定义</strong>： <span class="math inline">\(f:R-&gt;R\)</span> is convex if for all <span class="math inline">\(\alpha,\beta\geq 0\)</span> such that <span class="math inline">\(\alpha+\beta=1\)</span>,we have <span class="math inline">\(f(\alpha x+\beta y)\leq \alpha f(x)+\beta f(y)\)</span> for all <span class="math inline">\(x,y\in R\)</span>.</p><p><strong>Convexity lemma：</strong> Let <span class="math inline">\(f\)</span> be a convec function,and let <span class="math inline">\(\alpha_1,..,\alpha_n\)</span> be nonnegative real numbers such that<span class="math inline">\(\sum \alpha_k=1\)</span>, Then for any real numbers <span class="math inline">\(x_1,...,x_n\)</span>,we have<span class="math inline">\(f\left(\sum_{k=1}^{n} \alpha_{k} x_{k}\right) \leq \sum_{k=1}^{n} \alpha_{k} f\left(x_{k}\right)\)</span>.</p><p><strong>proof:</strong> 归纳法证明： <span class="math display">\[\begin{aligned}f\left(\sum_{k=1}^{n} \alpha_{k} x_{k}\right) &amp;=f\left(\alpha_{n} x_{n}+\left(1-\alpha_{n}\right) \sum_{k=1}^{n-1} \frac{\alpha_{k}}{1-\alpha_{n}} x_{k}\right) \\&amp; \leq \alpha_{n} f\left(x_{n}\right)+\left(1-\alpha_{n}\right) f\left(\sum_{k=1}^{n-1} \frac{\alpha_{k}}{1-\alpha_{n}} x_{k}\right) \\&amp; \leq \alpha_{n} f\left(x_{n}\right)+\left(1-\alpha_{n}\right) \sum_{k=1}^{n-1} \frac{\alpha_{k}}{1-\alpha_{n}} f\left(x_{k}\right)\\&amp;=\sum_{k=1}^{n} \alpha_{k} f\left(x_{k}\right)\\\end{aligned}\]</span></p><p><strong>Convexity lemma: infinite case</strong></p><p><img src="https://i.bmp.ovh/imgs/2021/03/9754b4c9b5591036.png" style="zoom:50%;" /></p><p>引申到 Jensen’s inequality：</p><p><img src="https://i.bmp.ovh/imgs/2021/03/19c4bf693ea251e6.png" style="zoom:50%;" /></p><p><strong>Analysis of BST height</strong></p><p>Let Xn be the random variable denoting the height of a randomly built binary search tree on n nodes, and let <span class="math inline">\(Y_n = 2^{X_n}\)</span> be its exponential height.</p><p>If the root of the tree has rank k, then <span class="math inline">\(X_n=1+max\{X_{k-1},X_{n-k}\}\)</span>.Hence, we have<span class="math inline">\(Y_n=2*\{maxY_{k-1},Y_{n-k}\}\)</span>.</p><p>Define the indicator random variable <span class="math inline">\(Z_{nk}\)</span> as :<span class="math inline">\(Z_{n k}=\left\{\begin{array}{ll} 1 &amp; \text { if the root has rank } k \\ 0 &amp; \text { otherwise. } \end{array}\right.\)</span></p><p>Thus, <span class="math inline">\(\operatorname{Pr}\{Z_{n k}=1\}=\mathrm{E}[Z_{n k}]=1/ n\)</span>, and <span class="math inline">\(Y_{n}=\sum_{k=1}^{n} Z_{n k}(2 \cdot \max \{Y_{k-1}, Y_{n-k}\})\)</span>.</p><p><span class="math display">\[\begin{aligned}E[Y_{n}] &amp;=E[\sum_{k=1}^{n} Z_{n k}(2 \cdot \max \{Y_{k-1}, Y_{n-k}\})] \\&amp;=\sum_{k=1}^{n} E[Z_{n k}(2 \cdot \max \{Y_{k-1}, Y_{n-k}\})] \\&amp;=2 \sum_{k=1}^{n} E[Z_{n k}] \cdot E[\max \{Y_{k-1}, Y_{n-k}\}] \\&amp; \leq \frac{2}{n} \sum_{k=1}^{n} E[Y_{k-1}+Y_{n-k}] \\&amp;=\frac{4}{n} \sum_{k=0}^{n-1} E\left[Y_{k}\right] &amp; \begin{array}{c}\text { Each term appears } \\\text { twice, and reindex }\end{array}\end{aligned}\]</span></p><p>采用替代法证明<span class="math inline">\(E[Y_n]\leq cn^3\)</span> for some positive constant.</p><p><span class="math display">\[\begin{aligned}E\left[Y_{n}\right] &amp;=\frac{4}{n} \sum_{k=0}^{n-1} E\left[Y_{k}\right] \\&amp; \leq \frac{4}{n} \sum_{k=0}^{n-1} c k^{3} \\&amp; \leq \frac{4 c}{n} \int_{0}^{n} x^{3} d x \\&amp;=\frac{4 c}{n}\left(\frac{n^{4}}{4}\right)\\&amp;=\mathrm{cn}^{3}\end{aligned}\]</span></p><p>Putting it all together, we have<span class="math inline">\(2^{E\left[X_{n}\right]} \leq E\left[2^{X_{n}}\right]=E[Y_n]\leq cn^3\)</span>,since <span class="math inline">\(f(x)=2^x\)</span>is convex</p><p>可得<span class="math inline">\(E[X_n]\leq 3\lg n+O(1)\)</span>.</p><h2 id="post-mortem">4. Post mortem</h2><p><img src="https://i.bmp.ovh/imgs/2021/03/e7fdfbc3719c0181.png" style="zoom:50%;" /></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;MIT算法导论课程：Lec09 二叉搜索树，对应书上的章节：Section 12.4&lt;/p&gt;</summary>
    
    
    
    <category term="算法导论MIT" scheme="http://example.com/categories/%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BAMIT/"/>
    
    
    <category term="学习笔记" scheme="http://example.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>Lec11 扩充的数据结构、动态有序统计和区间树</title>
    <link href="http://example.com/2021/03/28/Lec11%E6%89%A9%E5%85%85%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%81%E5%8A%A8%E6%80%81%E6%9C%89%E5%BA%8F%E7%BB%9F%E8%AE%A1%E5%92%8C%E5%8C%BA%E9%97%B4%E6%A0%91/"/>
    <id>http://example.com/2021/03/28/Lec11%E6%89%A9%E5%85%85%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%81%E5%8A%A8%E6%80%81%E6%9C%89%E5%BA%8F%E7%BB%9F%E8%AE%A1%E5%92%8C%E5%8C%BA%E9%97%B4%E6%A0%91/</id>
    <published>2021-03-28T08:14:57.000Z</published>
    <updated>2021-03-29T00:38:55.336Z</updated>
    
    <content type="html"><![CDATA[<p>MIT算法导论课程：Lec11 扩充的数据结构、动态有序统计和区间树，对应书上的章节：Chapter 14</p><span id="more"></span><h2 id="dynamic-order-statistics">1. Dynamic order statistics</h2><p>Augmenting Data Structures(扩充的数据结构)</p><p><strong>实现功能</strong></p><p><code>OS-SELECT(i, S)</code>: returns the <code>ith</code> smallest element in the dynamic set S</p><p><code>OS-RANK(x, S)</code>: returns the rank of x ∈ S in the sorted order of S’s elements.</p><p><strong>IDEA</strong>: 对set S采用红黑树，但是在节点里保存子树的大小。<code>size[x] = size[left[x]] + size[right[x]] + 1</code>.</p><p>实现的一个技巧：对NIL采用sentinel(dummy record)，<code>size[NIL]=0</code>.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">OS-SELECT(x,i) &#x2F;&#x2F;ith smallest element in the subtree rooted at x </span><br><span class="line"></span><br><span class="line">k&#x3D;size[left[x]]+1 &#x2F;&#x2F;k&#x3D;rank(x)</span><br><span class="line">if i&#x3D;k then return x</span><br><span class="line">if i&lt;k</span><br><span class="line">then return OS-SELECT(left[x],i)</span><br><span class="line">else return OS-SELECT(right[x],i-k)</span><br></pre></td></tr></table></figure><p>运行时间为<span class="math inline">\(O(h)=O(\lg n)\)</span>.</p><p>为什么保存树的大小而不是直接是值得rank，因为Insert和DELETE，当修改红黑树时，很难维护它们。插入或删除时更新子树大小。</p><p>插入时修改树的大小值，然后需要重新平衡。</p><ul><li><p>Recolorings: 对树的大小没有影响</p></li><li><p>Rotations: <span class="math inline">\(O(1)\)</span>的时间修复树</p><p><img src="https://i.bmp.ovh/imgs/2021/03/3dff42f57651aaf9.png" style="zoom:50%;" /></p></li></ul><h2 id="methodology">2. Methodology</h2><ol type="1"><li>选择基础数据结构（红黑树）。</li><li>确定要存储在数据结构中的其他信息（子树大小）</li><li>确认可以保留此信息以进行修改操作（RBINSERT，RB-DELETE-不要忘记轮换）。</li><li>开发使用该信息的新动态集操作（OS-SELECT和OS-RANK）。</li></ol><p>这些步骤是指导性的，而不是严格的规则。</p><h2 id="interval-trees">3. Interval trees</h2><p>目标：维护动态间隔集，例如时间间隔</p><p>Query：对于给定的查询间隔<code>i</code>，在集合中找到一个与<code>i</code>重叠的间隔。</p><p><strong>Following the methodology</strong></p><ol type="1"><li><p>选择基础数据结构：红黑树key设为低端点。</p></li><li><p>确定要存储在数据结构中的其他信息。在每个节点x中存储以<code>x</code>为根的子树中的最大值<code>m[x]</code>以及与该键对应的间隔<code>int[x]</code>。</p><p><img src="https://i.bmp.ovh/imgs/2021/03/d8e5f8156ad9ba3a.png" style="zoom:50%;" /></p></li><li><p>验证可以保留此信息以用于修改操作。</p><ol type="1"><li><p>Insert：沿着树插下来。</p></li><li><p>Rotations：修复需要<span class="math inline">\(O(1)\)</span>时间。</p><p><img src="https://i.bmp.ovh/imgs/2021/03/c0f5d6775e8f7f43.png" style="zoom:50%;" /></p></li></ol></li><li><p>开发使用该信息的新动态集操作。</p><p><img src="https://i.bmp.ovh/imgs/2021/03/b0ee510dd13b5e0f.png" style="zoom:50%;" /></p></li></ol><p><strong>Analysis</strong></p><p>查询一次需要<span class="math inline">\(O(\lg n)\)</span>，查询所有：搜索，列出，删除，重复。需要<span class="math inline">\(O(k\lg n)\)</span>，最好的算法为<span class="math inline">\(O(k+\lg n)\)</span>.</p><p><strong>Correctness</strong></p><p><img src="https://i.bmp.ovh/imgs/2021/03/c8ab820678489f8c.png" style="zoom:50%;" /></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;MIT算法导论课程：Lec11 扩充的数据结构、动态有序统计和区间树，对应书上的章节：Chapter 14&lt;/p&gt;</summary>
    
    
    
    <category term="算法导论MIT" scheme="http://example.com/categories/%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BAMIT/"/>
    
    
    <category term="学习笔记" scheme="http://example.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
</feed>
